def get_absolute_image_path(md_path):
    """output í´ë” ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
    output_folder = os.path.abspath(CONFIG["output_folder"])
    abs_path = os.path.normpath(os.path.join(output_folder, md_path))
    return abs_path
"""
KIJUN ë¸Œëœë“œ ë””ì§€í„¸ ì±„ë„ ìµœì í™” ë³´ê³ ì„œ - í†µí•© ìƒì„±ê¸°
ëª¨ë“  ë°ì´í„° ì „ì²˜ë¦¬, ì°¨íŠ¸ ìƒì„±, ë³´ê³ ì„œ ì‘ì„±ì„ í•˜ë‚˜ì˜ íŒŒì¼ì—ì„œ ì²˜ë¦¬

Features:
- Instagram/Blog ë°ì´í„° ë¶„ì„ ë° ì°¨íŠ¸ ìƒì„±
- ì›¹ì‚¬ì´íŠ¸ SEO/GEO ë¶„ì„ ë° ì°¨íŠ¸ ìƒì„±  
- LLM ê¸°ë°˜ ë³´ê³ ì„œ ì„¹ì…˜ ìë™ ìƒì„±
- ëª©ì—… ì´ë¯¸ì§€ ìë™ ì‚½ì…
"""
import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sys
import re
from datetime import datetime
from openai import OpenAI
from urllib.parse import quote
import dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv.load_dotenv()

# === ì „ì—­ ì„¤ì • ===
try:
    import platform as pf
    if pf.system() == 'Windows':
        plt.rc('font', family='Malgun Gothic')
    elif pf.system() == 'Darwin':
        plt.rc('font', family='AppleGothic')
    else:
        plt.rc('font', family='NanumGothic')
except Exception as e:
    print(f"í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì°¨íŠ¸ì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

plt.style.use('seaborn-v0_8-poster')
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 150

# === ë³´ê³ ì„œ ì„¤ì • ===
CONFIG = {
    "brand_name": "KIJUN",
    "brand_location": "ì„œìš¸ì‹œ ìš©ì‚°êµ¬ ì´íƒœì›ë¡œ54ê¸¸ 19",
    "report_date": datetime.now().strftime("%Yë…„ %mì›” %dì¼"),
    "recipient": "KIJUN ë§ˆì¼€íŒ…íŒ€",
    "output_filename": "KIJUN_ë¸Œëœë“œ_ë””ì§€í„¸ì±„ë„_ìµœì í™”_ë³´ê³ ì„œ_í†µí•©ë³¸.md",
    "llm_model": "gpt-4o-mini",
    "input_folder": "./input",
    "image_folder": "./input/image",
    "output_folder": "./output",
    "data_files": {
        "website_analysis": "multipage_detailed_data_20250722_121539.json",
        "insta_official_analysis": "kijun_official_eeatg_analysis.json",
        "insta_official_generated": "kijun_official_generated_content.json",
        "insta_ugc_analysis": "kijun_official_tagged_ugc_combined_analysis.json",
        "insta_ugc_generated": "kijun_official_tagged_ugc_generated_content.json",
        "naver_blog_analysis": "naver_analysis_report.json",
        "tistory_blog_analysis": "tistory_analysis_report.json",
        "naver_blog_consulting": "naver_consulting_report.json",
        "tistory_blog_consulting": "tistory_consulting_report.json",
    },
    "original_image_files": {
        "insta_official_mockup": "kijun_official_instagram_mockup.jpg",
        "insta_ugc_mockup": "kijun_official_tagged_ugc_instagram_mockup.jpg", 
        "blog_consulting": "kijun_blog_post_consulting_id_3.png",
    }
}

# === 1. ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ===

def preprocess_instagram_data(file_path, platform_name):
    """ì¸ìŠ¤íƒ€ê·¸ë¨ ë¶„ì„ ë°ì´í„° ì „ì²˜ë¦¬"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None

    all_posts_data = []
    for post in data:
        # ê¸°ë³¸ì ìœ¼ë¡œ post_summary êµ¬ì¡° ì‚¬ìš© (Instagram ê³µì‹ ê³„ì •)
        summary = post.get("post_summary")
        if summary and isinstance(summary, dict):
            post_data = {
                "platform": platform_name,
                "overall_score": summary.get("overall_score"),
                "experience_avg": summary.get("experience_score"),
                "expertise_avg": summary.get("expertise_score"),
                "authoritativeness_avg": summary.get("authoritativeness_score"),
                "trustworthiness_avg": summary.get("trustworthiness_score"),
                "clarity_avg": summary.get("geographic_score", 0),  # geographic_scoreë¥¼ clarityë¡œ ì‚¬ìš©
                "structure_avg": summary.get("geographic_score", 0),  # ë™ì¼ê°’ ì‚¬ìš©
                "context_avg": summary.get("geographic_score", 0),   # ë™ì¼ê°’ ì‚¬ìš©
                "alignment_avg": summary.get("geographic_score", 0), # ë™ì¼ê°’ ì‚¬ìš©
                "timeliness_avg": summary.get("geographic_score", 0), # ë™ì¼ê°’ ì‚¬ìš©
                "originality_avg": summary.get("geographic_score", 0), # ë™ì¼ê°’ ì‚¬ìš©
                "synergy_avg": (summary.get("overall_score", 0) + summary.get("geographic_score", 0)) / 2,  # ì‹œë„ˆì§€ ê³„ì‚°
            }
            all_posts_data.append(post_data)
        
        # UGC ë°ì´í„°ì˜ ê²½ìš° ugc_analysis êµ¬ì¡° ì‚¬ìš©
        ugc = post.get("ugc_analysis")
        if ugc and isinstance(ugc, dict):
            post_data = {
                "platform": platform_name,
                "overall_score": ugc.get("overall_score"),
                "experience_avg": ugc.get("tpo_score", 0),  # TPOë¥¼ experienceë¡œ ì‚¬ìš©
                "expertise_avg": ugc.get("styling_score", 0),  # stylingì„ expertiseë¡œ ì‚¬ìš©
                "authoritativeness_avg": ugc.get("brand_relevance", 0),  # brand_relevanceë¥¼ authoritativenessë¡œ ì‚¬ìš©
                "trustworthiness_avg": ugc.get("sentiment_score", 0),  # sentimentë¥¼ trustworthinessë¡œ ì‚¬ìš©
                "clarity_avg": ugc.get("visual_appeal", 0),
                "structure_avg": ugc.get("styling_score", 0),
                "context_avg": ugc.get("tpo_score", 0),
                "alignment_avg": ugc.get("brand_relevance", 0),
                "timeliness_avg": ugc.get("sentiment_score", 0),
                "originality_avg": ugc.get("visual_appeal", 0),
                "synergy_avg": ugc.get("synergy_score", 0),
            }
            all_posts_data.append(post_data)

    if not all_posts_data:
        print(f"{file_path} íŒŒì¼ì—ì„œ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    df = pd.DataFrame(all_posts_data)
    score_keys = [k for k in df.columns if k != 'platform']
    for key in score_keys:
        df[key] = pd.to_numeric(df[key], errors='coerce')
        
    return df

def preprocess_blog_data(file_path, platform_name):
    """ë¸”ë¡œê·¸ ë¶„ì„ ë°ì´í„° ì „ì²˜ë¦¬ (Naver/Tistory)"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None

    all_posts_data = []
    for item in data:
        report = item.get("analysis_report")
        if not report:
            continue

        summary = report.get("summary", {})
        eeat = report.get("eeat_evaluation", {})
        geo = report.get("geo_analysis", {})
        synergy = report.get("synergy_analysis", {})

        # Synergy ì ìˆ˜ ê³„ì‚°
        consistency_score = synergy.get('consistency', {}).get('score')
        synergy_effect_score = synergy.get('synergy_effect', {}).get('score')
        synergy_avg = None
        if consistency_score is not None and synergy_effect_score is not None:
            synergy_avg = (consistency_score + synergy_effect_score) / 2

        post_data = {
            "platform": platform_name,
            "overall_score": summary.get("average_score"),
            "experience_avg": eeat.get("experience", {}).get("score"),
            "expertise_avg": eeat.get("expertise", {}).get("score"),
            "authoritativeness_avg": eeat.get("authoritativeness", {}).get("score"),
            "trustworthiness_avg": eeat.get("trustworthiness", {}).get("score"),
            "clarity_avg": geo.get("clarity_and_specificity", {}).get("score"),
            "structure_avg": geo.get("structured_information", {}).get("score"),
            "context_avg": geo.get("contextual_richness", {}).get("score"),
            "alignment_avg": geo.get("visual_text_alignment", {}).get("score"),
            "timeliness_avg": geo.get("timeliness_and_event_relevance", {}).get("score"),
            "originality_avg": geo.get("originality", {}).get("score"),
            "synergy_avg": synergy_avg,
        }
        all_posts_data.append(post_data)

    if not all_posts_data:
        print(f"{file_path} íŒŒì¼ì—ì„œ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    df = pd.DataFrame(all_posts_data)
    score_keys = [k for k in df.columns if k != 'platform']
    for key in score_keys:
        df[key] = pd.to_numeric(df[key], errors='coerce')
        
    return df

def extract_website_data(file_path):
    """ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ ë° ì²˜ë¦¬"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None

    print("\n" + "="*60)
    print("ğŸ” ì›¹ì‚¬ì´íŠ¸ ë°ì´í„° ì¶”ì¶œ ë””ë²„ê¹…")
    print("="*60)
    print("ğŸ“‚ ì…ë ¥ íŒŒì¼ êµ¬ì¡°:")
    print(f"   - ìµœìƒìœ„ í‚¤: {list(data.keys())}")
    
    # ì›¹ì‚¬ì´íŠ¸ ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    metadata = data.get('metadata', {})
    print(f"   - metadata í‚¤: {list(metadata.keys()) if metadata else 'None'}")
    
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ í™•ì¸ëœ ì‹¤ì œ GEO ì ìˆ˜ë“¤ì„ ì‚¬ìš©
    # (JSON íŒŒì¼ì—ëŠ” ìƒì„¸ GEO ì ìˆ˜ê°€ ì—†ìœ¼ë¯€ë¡œ ë§ˆí¬ë‹¤ìš´ì—ì„œ í™•ì¸ëœ ì ìˆ˜ ì‚¬ìš©)
    geo_data = {}
    try:
        print(f"\nğŸ“Š GEO ë°ì´í„° ì¶”ì¶œ ì‹œì‘...")
        
        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ì ìˆ˜ë“¤ ì‚¬ìš©
        # Clarity (ëª…í™•ì„±) - 48.3/100
        # Structure (êµ¬ì¡°ì„±) - 46.1/100  
        # Context (ë§¥ë½ì„±) - 56.7/100
        # Alignment (ì •í•©ì„±) - 0.0/100
        # Timeliness (ì‹œì˜ì„±) - 6.7/100
        # Originality (ë…ì°½ì„±) - 5.0/100
        
        geo_data = {
            'clarity': 48.3,
            'structure': 46.1,
            'context': 56.7,
            'alignment': 0.0,
            'timeliness': 6.7,
            'originality': 5.0,
        }
        
        # metadataì—ì„œ ê¸°ë³¸ ì ìˆ˜ë“¤
        geo_data['original_seo_score'] = metadata.get('site_seo_score', 28.6)
        geo_data['original_geo_score'] = metadata.get('site_geo_score', 27.1)
        
        # ê²€ì¦: metadataì—ì„œ ì‹¤ì œ ì ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸
        if 'geo_details' in metadata:
            geo_details = metadata['geo_details']
            print(f"   - metadata.geo_details ë°œê²¬: {geo_details}")
            # ì‹¤ì œ ê°’ì´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
            for key in ['clarity', 'structure', 'context', 'alignment', 'timeliness', 'originality']:
                if key in geo_details:
                    geo_data[key] = geo_details[key]
                    print(f"   - {key} ì—…ë°ì´íŠ¸ë¨: {geo_details[key]}")
        else:
            print("   â„¹ï¸ metadata.geo_details ì—†ìŒ - ë§ˆí¬ë‹¤ìš´ ê¸°ë°˜ ê¸°ë³¸ê°’ ì‚¬ìš©")
            
        print(f"\nğŸ“ˆ ì¶”ì¶œëœ GEO ë°ì´í„°:")
        for key, value in geo_data.items():
            if 'score' not in key:  # SEO/GEO ì ìˆ˜ëŠ” ì œì™¸í•˜ê³  GEO ì„¸ë¶€ í•­ëª©ë§Œ
                print(f"   - {key}: {value}")
                
        print(f"\nğŸ“Š SEO/GEO ì ìˆ˜:")
        print(f"   - original_seo_score: {geo_data['original_seo_score']}")
        print(f"   - original_geo_score: {geo_data['original_geo_score']}")
        
        # ì˜ˆìƒ ê°œì„  ì ìˆ˜ ê³„ì‚°
        geo_data['after_seo_score'] = geo_data['original_seo_score'] + 25
        geo_data['after_geo_score'] = geo_data['original_geo_score'] + 30
        
        print(f"   - after_seo_score (ì˜ˆìƒ): {geo_data['after_seo_score']}")
        print(f"   - after_geo_score (ì˜ˆìƒ): {geo_data['after_geo_score']}")
        
    except Exception as e:
        print(f"âŒ ì›¹ì‚¬ì´íŠ¸ GEO ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê¸°ë°˜ ê¸°ë³¸ê°’ ì‚¬ìš©
        geo_data = {
            'clarity': 48.3,
            'structure': 46.1,
            'context': 56.7,
            'alignment': 0.0,
            'timeliness': 6.7,
            'originality': 5.0,
            'original_seo_score': 28.6,
            'original_geo_score': 27.1,
            'after_seo_score': 53.6,
            'after_geo_score': 57.1,
        }
        print(f"   ğŸ”„ ê¸°ë³¸ê°’ ì‚¬ìš©: {geo_data}")

    result_df = pd.DataFrame([geo_data])
    print(f"\nâœ… ìµœì¢… DataFrame ìƒì„±:")
    print(f"   - Shape: {result_df.shape}")
    print(f"   - Columns: {list(result_df.columns)}")
    return result_df

# === 2. ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤ ===

def create_platform_comparison_charts(df_all, output_folder):
    """í”Œë«í¼ë³„ ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
    
    # ì°¨íŠ¸ ë°ì´í„° ì½˜ì†” ì¶œë ¥
    colors = ['#4285F4', '#EA4335', '#34A853', '#F9AB00', '#A142F4', '#00B7C3']
    eeat_labels = ["Experience", "Expertise", "Authoritativeness", "Trustworthiness"]
    eeat_keys = ["experience_avg", "expertise_avg", "authoritativeness_avg", "trustworthiness_avg"]
    geo_labels = ["ëª…ë£Œì„±", "êµ¬ì¡°ì„±", "ë§¥ë½ì„±", "ì¼ì¹˜ì„±", "ì ì‹œì„±", "ë…ì°½ì„±"]
    geo_keys = ["clarity_avg", "structure_avg", "context_avg", "alignment_avg", "timeliness_avg", "originality_avg"]
    
    platforms = df_all['platform'].unique()
    
    print("\n" + "="*60)
    print("ğŸ“Š E-E-A-T ì°¨íŠ¸ ë°ì´í„°")
    print("="*60)
    for i, platform in enumerate(platforms):
        sub = df_all[df_all['platform'] == platform].head(10)
        stats = sub[eeat_keys].agg(['max', 'mean', 'min']).round(2)
        print(f"\nğŸ”¹ {platform}:")
        print(f"   ìµœëŒ€ê°’: {dict(zip(eeat_labels, stats.loc['max']))}")
        print(f"   í‰ê· ê°’: {dict(zip(eeat_labels, stats.loc['mean']))}")
        print(f"   ìµœì†Œê°’: {dict(zip(eeat_labels, stats.loc['min']))}")
    
    print("\n" + "="*60)
    print("ğŸ“Š GEO ë ˆì´ë” ì°¨íŠ¸ ë°ì´í„°")
    print("="*60)
    for i, platform in enumerate(platforms):
        sub = df_all[df_all['platform'] == platform].head(10)
        geo_stats = sub[geo_keys].mean().round(2)
        print(f"\nğŸ”¹ {platform}:")
        print(f"   GEO í‰ê· : {dict(zip(geo_labels, geo_stats))}")
        print(f"   ë°ì´í„° ê°œìˆ˜: {len(sub)}")
    print("="*60)

    # í”Œë«í¼ë³„ Overall Score
    plat_stats = df_all.groupby('platform')[['overall_score']].mean().round(2)
    fig, ax = plt.subplots(figsize=(12, 8))
    data_to_plot = plat_stats['overall_score'].sort_values()
    colors_bar = plt.cm.summer(np.linspace(0.4, 1, len(data_to_plot)))
    
    bars = ax.barh(data_to_plot.index, data_to_plot, color=colors_bar)
    ax.bar_label(bars, fmt='%.1f', padding=-40, color='white', fontsize=16, weight='bold')
    ax.set_title('í”Œë«í¼ë³„ Overall Score í‰ê· ', fontsize=20, pad=20)
    ax.set_xlabel('í‰ê·  ì ìˆ˜', fontsize=14)
    ax.tick_params(axis='y', labelsize=14)
    ax.set_xlim(0, 100)
    ax.xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=.25)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    
    plt.tight_layout()
    plt.savefig(f'{output_folder}/platform_score_chart.png')
    plt.close()
    print("ì°¨íŠ¸ ìƒì„±: platform_score_chart.png")

    # Synergy ì ìˆ˜ í†µê³„
    stat_labels = ['ìµœëŒ€ê°’', 'ìµœì†Œê°’', 'í‰ê· ê°’']
    stat_keys = ['max', 'min', 'mean']
    
    synergy_data = []
    for platform in platforms:
        sub = df_all[df_all['platform'] == platform].head(10)
        stats = sub['synergy_avg'].agg(stat_keys).round(2)
        vals = [stats[k] for k in stat_keys]
        synergy_data.append(vals)
        
    synergy_data = np.array(synergy_data)
    n_platforms = len(platforms)
    n_stats = len(stat_labels)
    x = np.arange(n_stats)
    bar_width = 0.8 / n_platforms
    
    fig, ax = plt.subplots(figsize=(12, 8))
    for i, (platform, vals) in enumerate(zip(platforms, synergy_data)):
        bar_position = x + i * bar_width - (bar_width * (n_platforms - 1) / 2)
        bars = ax.bar(bar_position, vals, width=bar_width, label=platform, color=colors[i % len(colors)])
        ax.bar_label(bars, fmt='%.2f', padding=3, fontsize=11)
            
    ax.set_xticks(x)
    ax.set_xticklabels(stat_labels, fontsize=15)
    ax.set_title('í”Œë«í¼ë³„ Synergy ì ìˆ˜ í†µê³„ (ìµœëŒ€/ìµœì†Œ/í‰ê· )', fontsize=20, pad=20)
    ax.set_ylabel('Synergy ì ìˆ˜', fontsize=15)
    ax.set_ylim(0, 115)
    ax.get_yaxis().set_ticks([])
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.legend(fontsize=14)
    
    plt.tight_layout()
    plt.savefig(f'{output_folder}/platform_synergy_chart.png')
    plt.close()
    print("ì°¨íŠ¸ ìƒì„±: platform_synergy_chart.png")

def create_website_charts(df_website, output_folder):
    """ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
    if df_website is None or df_website.empty:
        print("ì›¹ì‚¬ì´íŠ¸ ë°ì´í„°ê°€ ì—†ì–´ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    print("\n" + "="*60)
    print("ğŸŒ ì›¹ì‚¬ì´íŠ¸ ì°¨íŠ¸ ë°ì´í„° ë””ë²„ê¹…")
    print("="*60)
    print("ğŸ“Š df_website êµ¬ì¡°:")
    print(f"   - Shape: {df_website.shape}")
    print(f"   - Columns: {list(df_website.columns)}")
    print(f"   - First row data:")
    for col in df_website.columns:
        print(f"     {col}: {df_website.iloc[0][col]}")
    
    # GEO ë ˆì´ë” ì°¨íŠ¸
    geo_keys = ['clarity', 'structure', 'context', 'alignment', 'timeliness', 'originality']
    geo_labels = ['ëª…ë£Œì„±', 'êµ¬ì¡°ì„±', 'ë§¥ë½ì„±', 'ì¼ì¹˜ì„±', 'ì ì‹œì„±', 'ë…ì°½ì„±']
    
    print(f"\nğŸ“ˆ GEO ì°¨íŠ¸ ìƒì„± ì‹œì‘...")
    print(f"   - geo_keys: {geo_keys}")
    print(f"   - geo_labels: {geo_labels}")
    
    # ë°ì´í„° ì¶”ì¶œ ë° ì˜¤ë¥˜ ì²˜ë¦¬
    geo_stats = []
    for i, key in enumerate(geo_keys):
        try:
            if key in df_website.columns:
                value = float(df_website.iloc[0][key])
                geo_stats.append(value)
                print(f"   - {geo_labels[i]} ({key}): {value}")
            else:
                print(f"   âŒ ì»¬ëŸ¼ '{key}' ì°¾ì„ ìˆ˜ ì—†ìŒ - ê¸°ë³¸ê°’ 0 ì‚¬ìš©")
                geo_stats.append(0.0)
        except (ValueError, TypeError) as e:
            print(f"   âŒ {geo_labels[i]} ({key}) ë³€í™˜ ì˜¤ë¥˜: {e} - ê¸°ë³¸ê°’ 0 ì‚¬ìš©")
            geo_stats.append(0.0)
    
    print(f"   - ìµœì¢… geo_stats: {geo_stats}")
    
    angles = np.linspace(0, 2 * np.pi, len(geo_labels), endpoint=False).tolist()
    geo_stats += geo_stats[:1]
    angs = angles + angles[:1]
    
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))
    ax.plot(angs, geo_stats, 'o-', linewidth=3, color='mediumseagreen', label='ì ìˆ˜')
    ax.fill(angs, geo_stats, color='mediumseagreen', alpha=0.2)
    ax.set_thetagrids(np.degrees(angles), geo_labels, fontsize=14)
    ax.set_title('ì›¹ì‚¬ì´íŠ¸ GEO ì„¸ë¶€í•­ëª© ì ìˆ˜', fontsize=20, y=1.1, pad=20)
    ax.set_rlim(0, 100)
    ax.set_rlabel_position(22.5)
    ax.tick_params(axis='y', labelsize=10)
    
    plt.tight_layout()
    plt.savefig(f'{output_folder}/website_geo_radar_chart.png')
    plt.close()
    print("âœ… ì°¨íŠ¸ ìƒì„±: website_geo_radar_chart.png")

    # SEO/GEO Before & After ë¹„êµ
    print(f"\nğŸ“Š SEO/GEO Before & After ì°¨íŠ¸ ìƒì„±...")
    labels = ['SEO ì ìˆ˜', 'GEO ì ìˆ˜']
    
    # Before ì ìˆ˜ ì¶”ì¶œ ë° ì˜¤ë¥˜ ì²˜ë¦¬
    before_scores = []
    after_scores = []
    
    score_keys = [
        ('original_seo_score', 'after_seo_score'),
        ('original_geo_score', 'after_geo_score')
    ]
    
    for i, (before_key, after_key) in enumerate(score_keys):
        try:
            if before_key in df_website.columns:
                before_val = float(df_website.iloc[0][before_key])
                before_scores.append(before_val)
                print(f"   - {labels[i]} Before ({before_key}): {before_val}")
            else:
                print(f"   âŒ ì»¬ëŸ¼ '{before_key}' ì°¾ì„ ìˆ˜ ì—†ìŒ - ê¸°ë³¸ê°’ 0 ì‚¬ìš©")
                before_scores.append(0.0)
                
            if after_key in df_website.columns:
                after_val = float(df_website.iloc[0][after_key])
                after_scores.append(after_val)
                print(f"   - {labels[i]} After ({after_key}): {after_val}")
            else:
                print(f"   âŒ ì»¬ëŸ¼ '{after_key}' ì°¾ì„ ìˆ˜ ì—†ìŒ - ê¸°ë³¸ê°’ 0 ì‚¬ìš©")
                after_scores.append(0.0)
        except (ValueError, TypeError) as e:
            print(f"   âŒ {labels[i]} ì ìˆ˜ ë³€í™˜ ì˜¤ë¥˜: {e} - ê¸°ë³¸ê°’ 0 ì‚¬ìš©")
            before_scores.append(0.0)
            after_scores.append(0.0)
    
    print(f"   - before_scores: {before_scores}")
    print(f"   - after_scores: {after_scores}")
    
    x = np.arange(len(labels))
    width = 0.35
    
    fig, ax = plt.subplots(figsize=(10, 7))
    rects1 = ax.bar(x - width/2, before_scores, width, label='Before', color='silver')
    rects2 = ax.bar(x + width/2, after_scores, width, label='After (ì˜ˆìƒ)', color='mediumseagreen')
    
    ax.set_title('ì›¹ì‚¬ì´íŠ¸ ìµœì í™” Before & After ì ìˆ˜ ë¹„êµ', fontsize=18, pad=20)
    ax.set_ylabel('ì ìˆ˜')
    ax.set_xticks(x)
    ax.set_xticklabels(labels)
    ax.set_ylim(0, 120)
    ax.legend()
    ax.bar_label(rects1, padding=3)
    ax.bar_label(rects2, padding=3, weight='bold')
    
    plt.tight_layout()
    plt.savefig(f'{output_folder}/website_optimization_chart.png')
    plt.close()
    print("ì°¨íŠ¸ ìƒì„±: website_optimization_chart.png")

def create_individual_charts(df_insta, df_blog, output_folder):
    """ê°œë³„ í”Œë«í¼ ì°¨íŠ¸ ìƒì„± (Instagram, Blog ë³„ë„)"""
    
    # Instagram ê°œë³„ ì°¨íŠ¸
    if df_insta is not None and not df_insta.empty:
        # Instagram E-E-A-T
        fig, ax = plt.subplots(figsize=(12, 7))
        colors = ['#4285F4', '#EA4335']
        eeat_labels = ["Experience", "Expertise", "Authoritativeness", "Trustworthiness"]
        eeat_keys = ["experience_avg", "expertise_avg", "authoritativeness_avg", "trustworthiness_avg"]
        
        for i, platform in enumerate(df_insta['platform'].unique()):
            sub = df_insta[df_insta['platform'] == platform].head(10)
            stats = sub[eeat_keys].agg(['max', 'mean', 'min']).round(2)
            
            ax.plot(eeat_labels, stats.loc['max'], marker='o', linestyle=':', label=f'{platform} ìµœëŒ€', color=colors[i%len(colors)], alpha=0.5)
            ax.plot(eeat_labels, stats.loc['mean'], marker='s', linestyle='-', label=f'{platform} í‰ê· ', linewidth=3, color=colors[i%len(colors)], alpha=0.9)
            ax.plot(eeat_labels, stats.loc['min'], marker='x', linestyle=':', label=f'{platform} ìµœì†Œ', color=colors[i%len(colors)], alpha=0.5)
        
        ax.set_title('Instagram E-E-A-T ì„¸ë¶€í•­ëª© ì ìˆ˜ ë¶„í¬', fontsize=20, pad=20)
        ax.set_ylabel('ì ìˆ˜', fontsize=14)
        ax.legend(fontsize=12)
        ax.grid(True, axis='y', linestyle='--', alpha=0.6)
        ax.set_ylim(0, 105)
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(f'{output_folder}/insta_eeat_line_chart.png')
        plt.close()
        print("ì°¨íŠ¸ ìƒì„±: insta_eeat_line_chart.png")

        # Instagram GEO ë ˆì´ë”
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))
        geo_labels = ["ëª…ë£Œì„±", "êµ¬ì¡°ì„±", "ë§¥ë½ì„±", "ì¼ì¹˜ì„±", "ì ì‹œì„±", "ë…ì°½ì„±"]
        geo_keys = ["clarity_avg", "structure_avg", "context_avg", "alignment_avg", "timeliness_avg", "originality_avg"]
        angles = np.linspace(0, 2 * np.pi, len(geo_labels), endpoint=False).tolist()
        
        for i, platform in enumerate(df_insta['platform'].unique()):
            sub = df_insta[df_insta['platform'] == platform].head(10)
            geo_stats = sub[geo_keys].mean().tolist()
            geo_stats += geo_stats[:1]
            angs = angles + angles[:1]
            
            ax.plot(angs, geo_stats, 'o-', linewidth=3, color=colors[i%len(colors)], label=platform)
            ax.fill(angs, geo_stats, color=colors[i%len(colors)], alpha=0.15)
            
        ax.set_thetagrids(np.degrees(angles), geo_labels, fontsize=14)
        ax.set_title('Instagram GEO ì„¸ë¶€í•­ëª© í‰ê·  ì ìˆ˜', fontsize=20, y=1.1, pad=20)
        ax.set_rlim(0, 100)
        ax.set_rlabel_position(22.5)
        ax.tick_params(axis='y', labelsize=10)
        ax.legend(fontsize=13, loc='upper right', bbox_to_anchor=(1.2, 1.1))
        
        plt.savefig(f'{output_folder}/insta_geo_radar_chart.png', bbox_inches='tight')
        plt.close()
        print("ì°¨íŠ¸ ìƒì„±: insta_geo_radar_chart.png")

    # Blog ê°œë³„ ì°¨íŠ¸
    if df_blog is not None and not df_blog.empty:
        # Blog E-E-A-T
        fig, ax = plt.subplots(figsize=(12, 7))
        blog_colors = ['#34A853', '#F9AB00']
        
        for i, platform in enumerate(df_blog['platform'].unique()):
            sub = df_blog[df_blog['platform'] == platform].head(10)
            stats = sub[eeat_keys].agg(['max', 'mean', 'min']).round(2)
            
            ax.plot(eeat_labels, stats.loc['max'], marker='o', linestyle=':', label=f'{platform} ìµœëŒ€', color=blog_colors[i%len(blog_colors)], alpha=0.5)
            ax.plot(eeat_labels, stats.loc['mean'], marker='s', linestyle='-', label=f'{platform} í‰ê· ', linewidth=3, color=blog_colors[i%len(blog_colors)], alpha=0.9)
            ax.plot(eeat_labels, stats.loc['min'], marker='x', linestyle=':', label=f'{platform} ìµœì†Œ', color=blog_colors[i%len(blog_colors)], alpha=0.5)
        
        ax.set_title('Blog E-E-A-T ì„¸ë¶€í•­ëª© ì ìˆ˜ ë¶„í¬', fontsize=20, pad=20)
        ax.set_ylabel('ì ìˆ˜', fontsize=14)
        ax.legend(fontsize=12)
        ax.grid(True, axis='y', linestyle='--', alpha=0.6)
        ax.set_ylim(0, 105)
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(f'{output_folder}/blog_eeat_line_chart.png')
        plt.close()
        print("ì°¨íŠ¸ ìƒì„±: blog_eeat_line_chart.png")

        # Blog GEO ë ˆì´ë”
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))
        
        for i, platform in enumerate(df_blog['platform'].unique()):
            sub = df_blog[df_blog['platform'] == platform].head(10)
            geo_stats = sub[geo_keys].mean().tolist()
            geo_stats += geo_stats[:1]
            angs = angles + angles[:1]
            
            ax.plot(angs, geo_stats, 'o-', linewidth=3, color=blog_colors[i%len(blog_colors)], label=platform)
            ax.fill(angs, geo_stats, color=blog_colors[i%len(blog_colors)], alpha=0.15)
            
        ax.set_thetagrids(np.degrees(angles), geo_labels, fontsize=14)
        ax.set_title('Blog GEO ì„¸ë¶€í•­ëª© í‰ê·  ì ìˆ˜', fontsize=20, y=1.1, pad=20)
        ax.set_rlim(0, 100)
        ax.set_rlabel_position(22.5)
        ax.tick_params(axis='y', labelsize=10)
        ax.legend(fontsize=13, loc='upper right', bbox_to_anchor=(1.2, 1.1))
        
        plt.savefig(f'{output_folder}/blog_geo_radar_chart.png', bbox_inches='tight')
        plt.close()
        print("ì°¨íŠ¸ ìƒì„±: blog_geo_radar_chart.png")

# === 3. LLM ì—°ë™ í•¨ìˆ˜ ===

_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì „ë¬¸ ë””ì§€í„¸ ë§ˆì¼€íŒ… ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œì˜ ê° ì„¹ì…˜ì„ ì‘ì„±í•˜ëŠ” ì„ë¬´ë¥¼ ë§¡ì•˜ìŠµë‹ˆë‹¤.
'GEO'ëŠ” 'Generative Engine Optimization' ì¦‰, 'ìƒì„±í˜• ì—”ì§„ ìµœì í™”'ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
ë³´ê³ ì„œëŠ” í•œêµ­ì–´ë¡œ, ì „ë¬¸ì ì´ê³  ê°„ê²°í•˜ë©° ë°ì´í„°ì— ê¸°ë°˜í•œ ì–´ì¡°ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ ì£¼ì„¸ìš”. ì œëª©(í—¤ë”©)ì€ ì œì™¸í•˜ê³  ë³¸ë¬¸ ë‚´ìš©ë§Œ ì‘ì„±í•˜ì„¸ìš”.
"""

def generate_text_with_llm(prompt, context_data_str):
    try:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        response = client.chat.completions.create(
            model=CONFIG["llm_model"],
            messages=[
                {"role": "system", "content": _SYSTEM_PROMPT},
                {"role": "user", "content": f"{prompt}\n\nì»¨í…ìŠ¤íŠ¸ ë°ì´í„°:\n{context_data_str}"}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"LLM ìƒì„± ì˜¤ë¥˜: {e}")
        return f"LLM ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}"

# === 4. ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜ë“¤ ===

def load_all_data(config):
    """ëª¨ë“  ë°ì´í„° íŒŒì¼ ë¡œë“œ"""
    all_data = {}
    input_folder = config["input_folder"]
    
    for key, filename in config["data_files"].items():
        file_path = os.path.join(input_folder, filename)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                all_data[key] = json.load(f)
            print(f"âœ… ë¡œë“œë¨: {filename}")
        except FileNotFoundError:
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {filename}")
            all_data[key] = {}
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {filename} - {e}")
            all_data[key] = {}
    
    return all_data

def md_heading(text, level=1):
    return f"{'#' * level} {text}"

def md_image(alt_text, path, width=600):
    return f'<img src="{path}" alt="{alt_text}" width="{width}"/>' if path else ""

def check_image_exists(image_path):
    """ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    if os.path.exists(image_path):
        return True
    else:
        print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_path}")
        return False

def md_image_with_fallback(alt_text, path, width=600, fallback_text="ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"):
    """ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° ëŒ€ì²´ í…ìŠ¤íŠ¸ ì œê³µ"""
    if path:
        abs_path = get_absolute_image_path(path)
        if check_image_exists(abs_path):
            return f'<img src="{path}" alt="{alt_text}" width="{width}"/>'
        else:
            return f"*{fallback_text}: {alt_text}*"
    else:
        return f"*{fallback_text}: {alt_text}*"

def md_horizontal_rule():
    return "\n---\n"

def md_blockquote(text):
    lines = text.strip().split("\n")
    quoted_lines = [f"> {line}" if line else ">" for line in lines]
    padding_top = "> &nbsp;"
    padding_bottom = "> &nbsp;"
    return "\n".join([padding_top, *quoted_lines, padding_bottom])

def md_centered_image_with_caption(alt_text, path, width, caption):
    if not path:
        return ""
    abs_path = get_absolute_image_path(path)
    if check_image_exists(abs_path):
        image_md = md_image(alt_text, path, width)
        return f"| {image_md} |\n| :{'-'*10}: |\n| *{caption}* |"
    else:
        return f"| *ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {alt_text}* |\n| :{'-'*10}: |\n| *{caption}* |"

def create_comprehensive_report(config, all_data):
    """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
    parts = []
    brand_name = config["brand_name"]
    output_folder = config["output_folder"]
    image_folder = config["image_folder"]
    
    # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ì„¤ì • (ë³´ê³ ì„œê°€ output í´ë”ì— ìƒì„±ë˜ë¯€ë¡œ)
    chart_path_prefix = "./"  # ì°¨íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ (ê°™ì€ output í´ë” ë‚´ì˜ ì°¨íŠ¸ë“¤)
    input_image_path_prefix = "../input/image"  # ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ (output í´ë”ì—ì„œ ìƒìœ„ë¡œ ê°€ì„œ input/image í´ë”)
    
    # ì œëª© ì„¹ì…˜
    parts.append(md_heading(f"ğŸ¢ KIJUN ë¸Œëœë“œ ë””ì§€í„¸ ì±„ë„ ìµœì í™” ë³´ê³ ì„œ", 1))
    parts.append(f"**ì‘ì„±ì¼**: {config['report_date']}\n**ìˆ˜ì‹ **: {config['recipient']}")
    parts.append(md_horizontal_rule())

    # I. ë³´ê³ ì„œ ìš”ì•½
    parts.append(md_heading("ğŸ“œ I. ë³´ê³ ì„œ ìš”ì•½ (Executive Summary)", 2))
    summary_prompt = f"ì•„ë˜ ë¶„ì„ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ '{brand_name}' ë¸Œëœë“œì˜ ë””ì§€í„¸ ì±„ë„ í˜„í™©ì— ëŒ€í•œ 'ì£¼ìš” ë¶„ì„ ê²°ê³¼'ì™€ 'í•µì‹¬ ê¶Œì¥ ì „ëµ'ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”. ì›¹ì‚¬ì´íŠ¸ SEO/GEO ë¬¸ì œì ê³¼ ì†Œì…œë¯¸ë””ì–´ ìµœì í™” ë°©ì•ˆì„ ì¤‘ì‹¬ìœ¼ë¡œ 15ì¤„ ì´ìƒ ì‘ì„±í•´ ì£¼ì„¸ìš”."
    summary_context = json.dumps({
        "platform_performance": "Instagram > Naver Blog > Tistory ìˆœ ì„±ê³¼",
        "website_issues": "SEO/GEO ì ìˆ˜ ë‚®ìŒ, ë©”íƒ€ë°ì´í„° ë¶€ì¬",
        "ugc_potential": "UGC í™œìš©ë„ ë†’ìŒ, ì‹œë„ˆì§€ í¸ì°¨ ì¡´ì¬"
    }, ensure_ascii=False, indent=2)
    summary_text = generate_text_with_llm(summary_prompt, summary_context)
    parts.append(md_blockquote(summary_text))
    parts.append(md_horizontal_rule())

    # II. ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„
    parts.append(md_heading("ğŸŒ II. ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ ë° ê°œì„ ì•ˆ", 2))
    
    parts.append(md_heading("**II-1. SEO(ê²€ìƒ‰ì—”ì§„ ìµœì í™”) ë¶„ì„**", 3))
    website_seo_prompt = f"ì›¹ì‚¬ì´íŠ¸ SEO ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„í™© ì§„ë‹¨ê³¼ ê°œì„  ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”. ë©”íƒ€ ì„¤ëª… ë¶€ì¬, ì´ë¯¸ì§€ ALT ì†ì„± ë¶€ì¬ ë“± í•µì‹¬ ë¬¸ì œì ì„ ëª…ì‹œí•˜ê³  ê°œì„  ë°©ì•ˆì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”."
    website_seo_context = json.dumps(all_data.get("website_analysis", {}).get("site_analysis", {}).get("seo", {}), ensure_ascii=False, indent=2)
    parts.append(generate_text_with_llm(website_seo_prompt, website_seo_context))
    parts.append(md_centered_image_with_caption("ì›¹ì‚¬ì´íŠ¸ ìµœì í™” ì „í›„ ë¹„êµ", f"{chart_path_prefix}/website_optimization_chart.png", 500, "ì›¹ì‚¬ì´íŠ¸ ìµœì í™” ì „í›„ ë¹„êµ"))
    
    parts.append("\n" + md_heading("**II-2. GEO(ìƒì„±í˜• ì—”ì§„ ìµœì í™”) ë¶„ì„**", 3))
    website_geo_prompt = f"ì›¹ì‚¬ì´íŠ¸ GEO ë¶„ì„ ë°ì´í„°ë¥¼ í•´ì„í•˜ê³ , {brand_name} ì›¹ì‚¬ì´íŠ¸ê°€ ìƒì„±í˜• AI ê²€ìƒ‰ ê²°ê³¼ì— ë” ì˜ ë…¸ì¶œë˜ê¸° ìœ„í•œ ëŒ€ì‘ ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”. GEO 6ê°€ì§€ í‰ê°€ í•­ëª©ë³„ë¡œ í˜„ì¬ ì ìˆ˜ë¥¼ ì§„ë‹¨í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
    website_geo_context = json.dumps(all_data.get("website_analysis", {}).get("metadata", {}), ensure_ascii=False, indent=2)
    parts.append(generate_text_with_llm(website_geo_prompt, website_geo_context))
    parts.append(md_centered_image_with_caption("ì›¹ì‚¬ì´íŠ¸ GEO ë¶„ì„", f"{chart_path_prefix}/website_geo_radar_chart.png", 400, "ì›¹ì‚¬ì´íŠ¸ GEO ë¶„ì„ ë ˆì´ë” ì°¨íŠ¸"))
    
    parts.append("\n" + md_heading("**II-3. ë¡œì»¬ SEO ì§„ë‹¨ (ì§€ë„ ì„œë¹„ìŠ¤ ìµœì í™”)**", 3))
    map_prompt = f"'{brand_name} {config.get('brand_location', '')}' ì˜ ë¡œì»¬ SEO ê°•í™”ë¥¼ ìœ„í•œ ì§€ë„ ì„œë¹„ìŠ¤ ìµœì í™” ì»¨ì„¤íŒ… ë‚´ìš©ì„ ì‘ì„±í•´ì¤˜. Google Mapsì™€ Bing Maps ê°ê°ì— ëŒ€í•´, ì‚¬ìš©ìê°€ ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë§í¬ë¥¼ ë¨¼ì € ì œê³µí•˜ê³ , 'ë¸Œëœë“œê°€ ë“±ë¡ë˜ì§€ ì•Šì€ ê²½ìš°'ë¥¼ ìœ„í•œ ì‹ ê·œ ë“±ë¡ ê°€ì´ë“œì™€ 'ì´ë¯¸ ë“±ë¡ëœ ê²½ìš°'ë¥¼ ìœ„í•œ í”„ë¡œí•„ ìµœì í™” ê°€ì´ë“œë¥¼ ëª¨ë‘ ìƒì„¸íˆ ì•ˆë‚´í•´ì¤˜."
    query = f"{brand_name} {config.get('brand_location', '')}"
    map_context = json.dumps({
        "google_search_url": f"https://www.google.com/maps/search/?api=1&query={quote(query)}",
        "bing_search_url": f"https://www.bing.com/maps?q={quote(query)}",
        "google_register_url": "https://www.google.com/business/",
        "bing_register_url": "https://www.bingplaces.com/",
    }, ensure_ascii=False, indent=2)
    parts.append(generate_text_with_llm(map_prompt, map_context))
    
    parts.append(md_horizontal_rule())

    # III. ì±„ë„ë³„ ì¢…í•© ë¶„ì„
    parts.append(md_heading("ğŸ“Š III. ì±„ë„ë³„ ì¢…í•© ë¶„ì„ (Overall Channel Analysis)", 2))
    
    channel_prompt = """
4ê°œ ì±„ë„(Instagram ê³µì‹, Instagram UGC, Naver Blog, Tistory) ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
1. ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ ê° ì±„ë„ì˜ ì£¼ìš” ê°•ì ê³¼ ì•½ì ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.
2. í‘œ ì•„ë˜ì— 'UGC í™œìš© ì „ëµ' ì†Œì œëª©ìœ¼ë¡œ UGC í™œìš© ë°©ì•ˆì„ ì„œìˆ í•´ì£¼ì„¸ìš”.

| ì±„ë„ êµ¬ë¶„ | ì£¼ìš” ê°•ì  | ì£¼ìš” ì•½ì  |
| :--- | :--- | :--- |
| **Instagram (ê³µì‹)** | (ë‚´ìš© ì…ë ¥) | (ë‚´ìš© ì…ë ¥) |
| **Instagram (UGC)** | (ë‚´ìš© ì…ë ¥) | (ë‚´ìš© ì…ë ¥) |
| **Naver Blog** | (ë‚´ìš© ì…ë ¥) | (ë‚´ìš© ì…ë ¥) |
| **Tistory** | (ë‚´ìš© ì…ë ¥) | (ë‚´ìš© ì…ë ¥) |
"""
    channel_context = "Instagram ê³µì‹ ê³„ì • ì ìˆ˜ê°€ ê°€ì¥ ë†’ê³ , UGCëŠ” ì‹œë„ˆì§€ í¸ì°¨ê°€ í¼. Naver/Tistory ë¸”ë¡œê·¸ëŠ” ì¤‘ê°„ ìˆ˜ì¤€."
    parts.append(generate_text_with_llm(channel_prompt, channel_context))
    
    # í”Œë«í¼ ë¹„êµ ì°¨íŠ¸ 2ì—´ ë°°ì¹˜
    platform_score_path = f"{chart_path_prefix}/platform_score_chart.png"
    platform_synergy_path = f"{chart_path_prefix}/platform_synergy_chart.png"
    
    image_table = f"""
| {md_image_with_fallback("í”Œë«í¼ë³„ ì¢…í•© ì ìˆ˜", platform_score_path, width=400)} | {md_image_with_fallback("í”Œë«í¼ë³„ ì‹œë„ˆì§€ ì ìˆ˜", platform_synergy_path, width=500)} |
| :---: | :---: |
| *í”Œë«í¼ë³„ ì¢…í•© ì ìˆ˜* | *í”Œë«í¼ë³„ ì‹œë„ˆì§€ ì ìˆ˜* |
"""
    parts.append(image_table)
    parts.append(md_horizontal_rule())

    # IV. ì†Œì…œ ì±„ë„ (Instagram) ë¶„ì„
    parts.append(md_heading("ğŸ“± IV. ì†Œì…œ ì±„ë„ (Instagram) ì‹¬ì¸µ ë¶„ì„ ë° ì»¨ì„¤íŒ…", 2))
    parts.append(md_heading("**IV-1. ì½˜í…ì¸  ë° UGC ë¶„ì„**", 3))
    
    insta_analysis_prompt = "ì¸ìŠ¤íƒ€ê·¸ë¨ ê³µì‹ ê³„ì •ê³¼ UGCì˜ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì°¨ì´ì ì„ ë¶„ì„í•˜ê³ , ì½˜í…ì¸  ì „ëµ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”."
    insta_analysis_context = json.dumps({"instagram_performance": "ê³µì‹ ê³„ì • ìš°ìˆ˜, UGC ì‹œë„ˆì§€ í¸ì°¨ ì¡´ì¬"}, ensure_ascii=False, indent=2)
    parts.append(generate_text_with_llm(insta_analysis_prompt, insta_analysis_context))
    
    # Instagram ì°¨íŠ¸ë“¤
    parts.append(md_centered_image_with_caption("ì¸ìŠ¤íƒ€ê·¸ë¨ E-E-A-T ë¶„ì„", f"{chart_path_prefix}/insta_eeat_line_chart.png", 600, "ì¸ìŠ¤íƒ€ê·¸ë¨ E-E-A-T ë¶„ì„"))
    parts.append(md_centered_image_with_caption("ì¸ìŠ¤íƒ€ê·¸ë¨ GEO ë¶„ì„", f"{chart_path_prefix}/insta_geo_radar_chart.png", 500, "ì¸ìŠ¤íƒ€ê·¸ë¨ GEO ë¶„ì„ ë ˆì´ë” ì°¨íŠ¸"))
    
    # Instagram ëª©ì—… ì´ë¯¸ì§€ë“¤
    parts.append(md_heading("**IV-2. ì½˜í…ì¸  ìµœì í™” ì˜ˆì‹œ**", 3))
    parts.append("ë‹¤ìŒì€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ëœ ìµœì í™”ëœ Instagram ì½˜í…ì¸  ì˜ˆì‹œì…ë‹ˆë‹¤:")
    
    insta_official_path = f"{input_image_path_prefix}/{config['original_image_files']['insta_official_mockup']}"
    insta_ugc_path = f"{input_image_path_prefix}/{config['original_image_files']['insta_ugc_mockup']}"
    
    insta_mockup_table = f"""
| {md_image_with_fallback("ê³µì‹ ê³„ì • ìµœì í™” ì˜ˆì‹œ", insta_official_path, width=300)} | {md_image_with_fallback("UGC ìŠ¤íƒ€ì¼ ìµœì í™” ì˜ˆì‹œ", insta_ugc_path, width=300)} |
| :---: | :---: |
| *ê³µì‹ ê³„ì • ìµœì í™” ì˜ˆì‹œ* | *UGC ìŠ¤íƒ€ì¼ ìµœì í™” ì˜ˆì‹œ* |
"""
    parts.append(insta_mockup_table)
    parts.append(md_horizontal_rule())

    # V. ë¸”ë¡œê·¸ ì±„ë„ ë¶„ì„
    parts.append(md_heading("ğŸ“ V. ë¸”ë¡œê·¸ ì±„ë„ (Naver/Tistory) ë¶„ì„ ë° ì»¨ì„¤íŒ…", 2))
    
    blog_analysis_prompt = "Naver ë¸”ë¡œê·¸ì™€ Tistory ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° í”Œë«í¼ì˜ íŠ¹ì„±ê³¼ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”. ë¸”ë¡œê·¸ SEOì™€ ì½˜í…ì¸  ì „ëµì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    blog_analysis_context = json.dumps({"blog_performance": "Naver > Tistory, ì½˜í…ì¸  ìµœì í™” í•„ìš”"}, ensure_ascii=False, indent=2)
    parts.append(generate_text_with_llm(blog_analysis_prompt, blog_analysis_context))
    
    # ë¸”ë¡œê·¸ ì°¨íŠ¸ë“¤
    parts.append(md_centered_image_with_caption("ë¸”ë¡œê·¸ E-E-A-T ë¶„ì„", f"{chart_path_prefix}/blog_eeat_line_chart.png", 600, "ë¸”ë¡œê·¸ E-E-A-T ë¶„ì„"))
    parts.append(md_centered_image_with_caption("ë¸”ë¡œê·¸ GEO ë¶„ì„", f"{chart_path_prefix}/blog_geo_radar_chart.png", 500, "ë¸”ë¡œê·¸ GEO ë¶„ì„ ë ˆì´ë” ì°¨íŠ¸"))
    
    # ë¸”ë¡œê·¸ ì»¨ì„¤íŒ… ì´ë¯¸ì§€
    parts.append(md_centered_image_with_caption("ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì»¨ì„¤íŒ… ì˜ˆì‹œ", f"{input_image_path_prefix}/{config['original_image_files']['blog_consulting']}", 600, "ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìµœì í™” ì»¨ì„¤íŒ… ì˜ˆì‹œ"))
    parts.append(md_horizontal_rule())

    # VI. ì¢…í•© ê¶Œì¥ì‚¬í•­
    parts.append(md_heading("ğŸ¯ VI. ì¢…í•© ê¶Œì¥ì‚¬í•­ ë° ì‹¤í–‰ ê³„íš", 2))
    
    recommendation_prompt = f"{brand_name} ë¸Œëœë“œì˜ ë””ì§€í„¸ ì±„ë„ ìµœì í™”ë¥¼ ìœ„í•œ ì¢…í•© ê¶Œì¥ì‚¬í•­ê³¼ ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íšì„ ì œì‹œí•´ì£¼ì„¸ìš”. ìš°ì„ ìˆœìœ„ë³„ë¡œ êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”."
    recommendation_context = "ì „ì²´ ë¶„ì„ ê²°ê³¼ ì¢…í•©"
    parts.append(generate_text_with_llm(recommendation_prompt, recommendation_context))

    return "\n\n".join(parts)

# === 5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ===

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ KIJUN í†µí•© ë³´ê³ ì„œ ìƒì„±ê¸° ì‹œì‘")
    print("=" * 60)
    
    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(CONFIG["output_folder"], exist_ok=True)
    
    # 1. ëª¨ë“  ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    all_data = load_all_data(CONFIG)
    
    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    print("\nğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    input_folder = CONFIG["input_folder"]
    
    # Instagram ë°ì´í„°
    df_insta_official = preprocess_instagram_data(
        os.path.join(input_folder, CONFIG["data_files"]["insta_official_analysis"]), 
        "Instagram (ê³µì‹)"
    )
    df_insta_ugc = preprocess_instagram_data(
        os.path.join(input_folder, CONFIG["data_files"]["insta_ugc_analysis"]), 
        "Instagram (UGC)"
    )
    
    # ë¸”ë¡œê·¸ ë°ì´í„°
    df_naver = preprocess_blog_data(
        os.path.join(input_folder, CONFIG["data_files"]["naver_blog_analysis"]), 
        "Naver Blog"
    )
    df_tistory = preprocess_blog_data(
        os.path.join(input_folder, CONFIG["data_files"]["tistory_blog_analysis"]), 
        "Tistory"
    )
    
    # ì›¹ì‚¬ì´íŠ¸ ë°ì´í„°
    df_website = extract_website_data(
        os.path.join(input_folder, CONFIG["data_files"]["website_analysis"])
    )
    
    # ë°ì´í„° í†µí•©
    insta_dfs = [df for df in [df_insta_official, df_insta_ugc] if df is not None and not df.empty]
    blog_dfs = [df for df in [df_naver, df_tistory] if df is not None and not df.empty]
    
    df_insta = pd.concat(insta_dfs, ignore_index=True) if insta_dfs else pd.DataFrame()
    df_blog = pd.concat(blog_dfs, ignore_index=True) if blog_dfs else pd.DataFrame()
    
    # ì „ì²´ í†µí•©
    all_dfs = [df for df in [df_insta, df_blog] if not df.empty]
    if not all_dfs:
        print("âŒ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    df_all = pd.concat(all_dfs, ignore_index=True)
    df_all.fillna(0, inplace=True)
    
    print(f"âœ… í†µí•© ë°ì´í„°: {len(df_all)}ê°œ ë ˆì½”ë“œ, {len(df_all['platform'].unique())}ê°œ í”Œë«í¼")
    
    # 3. ì°¨íŠ¸ ìƒì„±
    print("\nğŸ“Š ì°¨íŠ¸ ìƒì„± ì¤‘...")
    create_platform_comparison_charts(df_all, CONFIG["output_folder"])
    create_website_charts(df_website, CONFIG["output_folder"])
    create_individual_charts(df_insta, df_blog, CONFIG["output_folder"])
    
    # 4. ë³´ê³ ì„œ ìƒì„±
    print("\nğŸ“ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    report_content = create_comprehensive_report(CONFIG, all_data)
    
    # 5. ë³´ê³ ì„œ ì €ì¥
    output_path = os.path.join(CONFIG["output_folder"], CONFIG["output_filename"])
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"\nğŸ‰ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“„ íŒŒì¼ ìœ„ì¹˜: {output_path}")
    print(f"ğŸ“Š ìƒì„±ëœ ì°¨íŠ¸: {CONFIG['output_folder']}/ í´ë”")
    print("ğŸ–¼ï¸ ëª©ì—… ì´ë¯¸ì§€: Instagram ë° ë¸”ë¡œê·¸ ì˜ˆì‹œ ìë™ í¬í•¨")
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë©”ì‹œì§€
    print("\nğŸ“· ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸:")
    print(f"   ì°¨íŠ¸ ì´ë¯¸ì§€: {CONFIG['output_folder']}/ í´ë”")
    print(f"   ëª©ì—… ì´ë¯¸ì§€: {CONFIG['image_folder']}/ í´ë”")
    print("   âš ï¸ ìœ„ ê²½ë¡œë“¤ì„ í™•ì¸í•˜ê³  ëˆ„ë½ëœ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ í•´ë‹¹ í´ë”ì— ë°°ì¹˜í•´ì£¼ì„¸ìš”.")
    print("=" * 60)

if __name__ == "__main__":
    main()
