"""
Content analysis tools for Instagram posts
"""

import os
import json
import re
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()


def analyze_single_file(filename):
    """1ë‹¨ê³„: ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
    print(f"\nğŸ“Š 1ë‹¨ê³„: {filename} ë¶„ì„ ì‹œì‘")
    
    # API í‚¤ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ OpenAI API í‚¤ê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    print(f"âœ… OpenAI API í‚¤ í™•ì¸ë¨: {api_key[:10]}...")
    client = OpenAI(api_key=api_key)
    
    if not os.path.exists(filename):
        print(f"âš ï¸ {filename} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(data)}ê°œ ê²Œì‹œë¬¼")
        
        # UGC ì—¬ë¶€ íŒë‹¨
        is_ugc_dataset = 'tagged' in filename.lower()
        print(f"ğŸ“‹ ë°ì´í„°ì…‹ ìœ í˜•: {'UGC í¬í•¨' if is_ugc_dataset else 'ê³µì‹ ê²Œì‹œë¬¼ ì „ìš©'}")
        
        detailed_analyses = []
        
        # ëª¨ë“  ê²Œì‹œë¬¼ ë¶„ì„ (12ê°œ ì „ì²´)
        for i, post in enumerate(data, 1):
            print(f"ğŸ“ ê²Œì‹œë¬¼ {i}/{len(data)} ë¶„ì„ ì¤‘...")
            
            url = post.get('href', '')
            content = post.get('content', '')
            date = post.get('date', '')
            comments = post.get('comments', [])
            
            print(f"  ğŸ“ URL: {url[:50]}...")
            print(f"  ğŸ·ï¸ íƒ€ì…: {'UGC' if is_ugc_dataset else 'ê³µì‹ ê²Œì‹œë¬¼'}")
            
            if is_ugc_dataset:
                analysis_prompt = _create_ugc_analysis_prompt(url, content, date, len(comments))
            else:
                analysis_prompt = _create_official_analysis_prompt(url, content, date, len(comments))
            
            try:
                # OpenAI API í˜¸ì¶œ
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "You are an expert marketing analyst specializing in Instagram content analysis."},
                        {"role": "user", "content": analysis_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=1500
                )
                
                analysis_text = response.choices[0].message.content
                print(f"  ğŸ¤– LLM ë¶„ì„ ì™„ë£Œ")
                
                # JSON íŒŒì‹± ì‹œë„
                analysis_json = _parse_analysis_json(analysis_text, i)
                        
            except Exception as e:
                print(f"  âŒ LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
                # API ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                analysis_json = {
                    "overall_score": 75,
                    "summary": f"ê²Œì‹œë¬¼ {i} ë¶„ì„ ì˜¤ë¥˜",
                    "overall_suggestion": f"ê²Œì‹œë¬¼ {i} ê°œì„  í•„ìš”"
                }
            
            post_analysis = {
                "post_url": url,
                "original_post_data": {
                    "number": i,
                    "href": url,
                    "content": content,
                    "img": post.get('img', []),
                    "comments": comments,
                    "date": date
                },
                "post_summary": analysis_json
            }
            
            # UGC ë¶„ì„ì¸ ê²½ìš° ì¶”ê°€ í•„ë“œ ì €ì¥
            if is_ugc_dataset and 'product_guess' in analysis_json:
                post_analysis['ugc_analysis'] = analysis_json
            
            detailed_analyses.append(post_analysis)
            score = analysis_json.get('overall_score', 75)
            print(f"  âœ… ì™„ë£Œ - ì ìˆ˜: {score}/100ì ")
        
        # ì ìˆ˜ë³„ ì •ë ¬
        sorted_analyses = sorted(detailed_analyses, key=lambda x: x['post_summary']['overall_score'])
        
        # í•˜ìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ì— ëŒ€í•œ ê°œì„ ì•ˆ ìƒì„±
        low_score_posts = sorted_analyses[:2]
        low_score_revisions = []
        
        print(f"\nğŸ’¡ í•˜ìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ê°œì„ ì•ˆ ìƒì„± ì¤‘...")
        
        for post in low_score_posts:
            revision_data = _generate_revision(client, post)
            low_score_revisions.append(revision_data)
        
        # ìƒìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ì„±ê³µ ìš”ì¸ ë¶„ì„
        high_score_posts = sorted_analyses[-2:] if len(sorted_analyses) >= 2 else sorted_analyses[-1:]
        high_score_analyses = []
        
        print(f"\nğŸ† ìƒìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ì„±ê³µ ìš”ì¸ ë¶„ì„ ì¤‘...")
        
        for post in high_score_posts:
            success_data = _analyze_success_factors(client, post)
            high_score_analyses.append(success_data)
        
        # íŒŒì¼ëª… ê²°ì •
        base_name = filename.replace('.json', '')
        
        # UGC í¬í•¨ ì—¬ë¶€ í™•ì¸
        ugc_count = len([p for p in detailed_analyses if 'ugc_analysis' in p])
        has_ugc = ugc_count > 0
        
        if has_ugc:
            analysis_filename = os.path.join('output', f'{base_name}_ugc_combined_analysis.json')
            content_filename = os.path.join('output', f'{base_name}_ugc_generated_content.json')
            print(f"ğŸ’¡ UGC í¬í•¨ ë¶„ì„ìœ¼ë¡œ íŒŒì¼ëª…: {analysis_filename}")
        else:
            analysis_filename = os.path.join('output', f'{base_name}_eeatg_analysis.json')
            content_filename = os.path.join('output', f'{base_name}_generated_content.json')
            print(f"ğŸ’¡ ê³µì‹ ê²Œì‹œë¬¼ ì „ìš© ë¶„ì„ íŒŒì¼ëª…: {analysis_filename}")
        
        # ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥
        with open(analysis_filename, 'w', encoding='utf-8') as f:
            json.dump(detailed_analyses, f, ensure_ascii=False, indent=4)
        
        # ì½˜í…ì¸  íŒŒì¼ ì €ì¥
        content_suggestions = {
            "low_score_revisions": low_score_revisions,
            "high_score_analyses": high_score_analyses
        }
        
        with open(content_filename, 'w', encoding='utf-8') as f:
            json.dump(content_suggestions, f, ensure_ascii=False, indent=4)
        
        print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ - íŒŒì¼ ì €ì¥:")
        print(f"  ğŸ“Š ë¶„ì„ íŒŒì¼: {analysis_filename}")
        print(f"  ğŸ’¡ ì½˜í…ì¸  íŒŒì¼: {content_filename}")
        return content_filename
        
    except Exception as e:
        print(f"âŒ {filename} ë¶„ì„ ì‹¤íŒ¨: {e}")
        return False


def _create_ugc_analysis_prompt(url, content, date, comments_count):
    """UGC ìƒì„¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""
    You are a 'Senior Marketing Strategist' analyzing a KIJUN brand UGC Instagram post.
    Perform a comprehensive 3-step analysis and provide final scoring.
    
    POST DATA:
    URL: {url}
    Caption: {content}
    Date: {date}
    Comments: {comments_count}
    
    STEP 1 - Product & TPO Analysis:
    From the image and caption, identify the KIJUN product and analyze the TPO (Time, Place, Occasion).
    Score how well the product fits the TPO situation (1-100).
    
    STEP 2 - Styling Analysis:
    Define the styling mood, list paired items, and score the styling creativity (1-100).
    Focus on how creatively the KIJUN item is styled with other pieces.
    
    STEP 3 - Sentiment Analysis:
    Analyze the user's emotional expression and satisfaction level (0-100 points).
    Look for positive emotions, satisfaction indicators, and brand affinity.
    
    Provide your analysis in JSON format with detailed Korean explanations:
    {{
        "product_guess": "ì¶”ì • ì œí’ˆëª…",
        "tpo_analysis": "TPO ìƒí™© ë¶„ì„",
        "tpo_score": ì ìˆ˜ (0-100),
        "tpo_reason": "TPO ì ì ˆì„± í‰ê°€ ì´ìœ ",
        "styling_mood": "ìŠ¤íƒ€ì¼ë§ ë¬´ë“œ ì •ì˜",
        "paired_items": "í•¨ê»˜ ë§¤ì¹˜ëœ ì•„ì´í…œë“¤",
        "styling_score": ì ìˆ˜ (0-100),
        "styling_reason": "ìŠ¤íƒ€ì¼ë§ ì°½ì˜ì„± í‰ê°€ ì´ìœ ",
        "sentiment_score": ì ìˆ˜ (0-100),
        "sentiment_reason": "ê°ì •ì  ì–´í•„ ë° ë§Œì¡±ë„ ë¶„ì„",
        "brand_relevance": ì ìˆ˜ (0-100),
        "brand_reason": "ë¸Œëœë“œ ì—°ê´€ì„± ë° ì¶©ì„±ë„ ë¶„ì„",
        "visual_appeal": ì ìˆ˜ (0-100),
        "visual_reason": "ì‹œê°ì  ë§¤ë ¥ë„ í‰ê°€",
        "synergy_score": ì ìˆ˜ (0-100),
        "synergy_reason": "ì´ë¯¸ì§€ì™€ ìº¡ì…˜ì˜ ì—°ê²°ì„± ë¶„ì„",
        "overall_score": í‰ê· ì ìˆ˜ (0-100),
        "summary": "UGC ì „ì²´ ìš”ì•½ ë° ë¸Œëœë“œ ê°€ì¹˜",
        "overall_suggestion": "UGC í™œìš© ë° ë¸Œëœë“œ ë§ˆì¼€íŒ… ì œì•ˆ"
    }}
    """


def _create_official_analysis_prompt(url, content, date, comments_count):
    """ê³µì‹ ê²Œì‹œë¬¼ E-E-A-T-GEO ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""
    You are a 'Senior Digital Marketing Analyst' analyzing official KIJUN Instagram content.
    Perform comprehensive E-E-A-T-GEO analysis and provide detailed scoring.
    
    POST DATA:
    URL: {url}
    Caption: {content}
    Date: {date}
    Comments: {comments_count}
    
    ANALYSIS FRAMEWORK (E-E-A-T-GEO):
    - Experience: User experience quality
    - Expertise: Fashion expertise demonstration  
    - Authoritativeness: Brand authority signals
    - Trustworthiness: Content credibility
    - Geographic: Location/cultural relevance
    
    Provide detailed analysis in JSON format with Korean explanations:
    {{
        "experience_score": ì ìˆ˜ (0-100),
        "experience_reason": "ì‚¬ìš©ì ê²½í—˜ í’ˆì§ˆ ë¶„ì„",
        "expertise_score": ì ìˆ˜ (0-100),
        "expertise_reason": "íŒ¨ì…˜ ì „ë¬¸ì„± ì‹œì—° ë¶„ì„",
        "authoritativeness_score": ì ìˆ˜ (0-100),
        "authoritativeness_reason": "ë¸Œëœë“œ ê¶Œìœ„ì„± ì‹ í˜¸ ë¶„ì„",
        "trustworthiness_score": ì ìˆ˜ (0-100),
        "trustworthiness_reason": "ì½˜í…ì¸  ì‹ ë¢°ì„± ë¶„ì„",
        "geographic_score": ì ìˆ˜ (0-100),
        "geographic_reason": "ì§€ë¦¬ì /ë¬¸í™”ì  ì—°ê´€ì„± ë¶„ì„",
        "overall_score": í‰ê· ì ìˆ˜ (0-100),
        "summary": "E-E-A-T-GEO ì „ì²´ ë¶„ì„ ìš”ì•½",
        "overall_suggestion": "ì½˜í…ì¸  ê°œì„  ë° ìµœì í™” ì œì•ˆ"
    }}
    """


def _parse_analysis_json(analysis_text, post_number):
    """ë¶„ì„ ê²°ê³¼ JSON íŒŒì‹±"""
    try:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë” ìœ ì—°í•œ ë°©ë²•)
        # ì¤‘ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ JSON íŒ¨í„´ ì°¾ê¸°
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        json_matches = re.findall(json_pattern, analysis_text, re.DOTALL)
        
        if json_matches:
            # ê°€ì¥ ê¸´ JSON ë¬¸ìì—´ ì„ íƒ
            json_text = max(json_matches, key=len)
            analysis_json = json.loads(json_text)
        else:
            # ì§ì ‘ JSON ì‹œì‘/ë ì°¾ê¸°
            json_start = analysis_text.find('{')
            json_end = analysis_text.rfind('}') + 1
            if json_start != -1 and json_end > json_start:
                json_text = analysis_text[json_start:json_end]
                analysis_json = json.loads(json_text)
            else:
                raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
    except Exception as json_error:
        print(f"  âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ ({json_error}) - ê¸°ë³¸ê°’ ì‚¬ìš©")
        # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
        analysis_json = {
            "overall_score": 75,
            "summary": f"ê²Œì‹œë¬¼ {post_number} LLM ë¶„ì„ ì™„ë£Œ (íŒŒì‹± ì˜¤ë¥˜)",
            "overall_suggestion": f"ê²Œì‹œë¬¼ {post_number} ê°œì„  ì œì•ˆ"
        }
    
    return analysis_json


def _generate_revision(client, post):
    """í•˜ìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ê°œì„ ì•ˆ ìƒì„±"""
    print(f"  ğŸ“ í•˜ìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ê°œì„ ì•ˆ ìƒì„± ì¤‘...")
    
    revision_prompt = f"""
    You are a senior Creative Director for the fashion brand 'KIJUN'.
    An underperforming post needs revision based on comprehensive analysis.
    
    ORIGINAL POST DATA:
    URL: {post['post_url']}
    Original Caption: {post['original_post_data']['content']}
    Current Score: {post['post_summary']['overall_score']}
    Analysis Summary: {post['post_summary']['summary']}
    Improvement Suggestions: {post['post_summary']['overall_suggestion']}
    
    POST TYPE: {'UGC' if 'ugc_analysis' in post else 'Official Brand Post'}
    
    TASK: Based on the analysis findings, create improved content that addresses the low-scoring areas.
    Focus on improving E-E-A-T-GEO factors (for official posts) or UGC engagement factors (for UGC posts).
    
    **CRITICAL INSTRUCTION: Your entire response MUST be in KOREAN and in Key-Value format with '|||' as separator.**
    
    Key-Value Format Example:
    new_caption_v1: (ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ ê°œì„ ëœ ìº¡ì…˜ ë²„ì „ 1)
    |||
    new_caption_v2: (ë‹¤ë¥¸ ì ‘ê·¼ë²•ì˜ ê°œì„ ëœ ìº¡ì…˜ ë²„ì „ 2)
    |||
    hashtags: #í‚¤ì¤€ #ë””ìì´ë„ˆë¸Œëœë“œ #ì‹ ìƒí’ˆ (ìƒˆë¡œìš´ ì»¨ì…‰ì— ìµœì í™”ëœ í•´ì‹œíƒœê·¸)
    |||
    new_image_idea: (ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œì•ˆí•˜ëŠ” ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì»¨ì…‰ ë° êµ¬ì„± ì•„ì´ë””ì–´)
    |||
    original_post_url: {post['post_url']}
    """
    
    try:
        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a creative director specializing in fashion brand content creation."},
                {"role": "user", "content": revision_prompt}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        
        revision_text = response.choices[0].message.content
        print(f"    ğŸ¤– LLM ê°œì„ ì•ˆ ìƒì„± ì™„ë£Œ")
        
        # Key-Value í˜•ì‹ íŒŒì‹±
        revision_data = {"original_post_url": post['post_url']}
        
        # '|||'ë¡œ ë¶„í• í•˜ì—¬ íŒŒì‹±
        pairs = revision_text.split('|||')
        for pair in pairs:
            if ':' in pair:
                key, value = pair.split(':', 1)
                key = key.strip()
                value = value.strip()
                revision_data[key] = value
        
        # í•„ìˆ˜ í‚¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
        if 'new_caption_v1' not in revision_data:
            revision_data['new_caption_v1'] = "KIJUN ì‹ ìƒí’ˆ ì»¬ë ‰ì…˜ ëŸ°ì¹­! ì„¸ë ¨ëœ ë””ìì¸ê³¼ í¸ì•ˆí•œ ì°©ìš©ê°ì„ ë™ì‹œì— ë§Œì¡±ì‹œí‚¤ëŠ” í”„ë¦¬ë¯¸ì—„ ì˜ë¥˜ ë¸Œëœë“œì…ë‹ˆë‹¤. ğŸ’«"
        
        if 'hashtags' not in revision_data:
            revision_data['hashtags'] = "#í‚¤ì¤€ #KIJUN #ë””ìì´ë„ˆë¸Œëœë“œ #ì‹ ìƒí’ˆ #íŒ¨ì…˜ #ìŠ¤íƒ€ì¼ #í”„ë¦¬ë¯¸ì—„ì˜ë¥˜"
        
        if 'new_image_idea' not in revision_data:
            revision_data['new_image_idea'] = "Modern fashion lifestyle photography featuring KIJUN clothing in a minimalist Korean aesthetic setting"
        
        return revision_data
        
    except Exception as e:
        print(f"    âŒ LLM ê°œì„ ì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        # API ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
        return {
            "new_caption_v1": "KIJUN ì‹ ìƒí’ˆ ì»¬ë ‰ì…˜ ëŸ°ì¹­! ì„¸ë ¨ëœ ë””ìì¸ê³¼ í¸ì•ˆí•œ ì°©ìš©ê°ì„ ë™ì‹œì— ë§Œì¡±ì‹œí‚¤ëŠ” í”„ë¦¬ë¯¸ì—„ ì˜ë¥˜ ë¸Œëœë“œì…ë‹ˆë‹¤. ğŸ’«",
            "hashtags": "#í‚¤ì¤€ #KIJUN #ë””ìì´ë„ˆë¸Œëœë“œ #ì‹ ìƒí’ˆ #íŒ¨ì…˜ #ìŠ¤íƒ€ì¼ #í”„ë¦¬ë¯¸ì—„ì˜ë¥˜",
            "new_image_idea": "Modern fashion lifestyle photography featuring KIJUN clothing in a minimalist Korean aesthetic setting",
            "original_post_url": post['post_url']
        }


def _analyze_success_factors(client, post):
    """ìƒìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ì„±ê³µ ìš”ì¸ ë¶„ì„"""
    print(f"  ğŸ† ìƒìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ì„±ê³µ ìš”ì¸ ë¶„ì„ ì¤‘...")
    
    success_prompt = f"""
    You are a 'Lead Content Strategist' analyzing a high-performing KIJUN Instagram post.
    Identify the key success factors based on comprehensive performance analysis.
    
    HIGH-PERFORMING POST DATA:
    URL: {post['post_url']}
    Caption: {post['original_post_data']['content']}
    Excellent Score: {post['post_summary']['overall_score']}
    Analysis Summary: {post['post_summary']['summary']}
    
    POST TYPE: {'UGC' if 'ugc_analysis' in post else 'Official Brand Post'}
    
    TASK: Analyze WHY this post was highly effective and extract actionable insights.
    Focus on the strongest performing elements that can be replicated in future content.
    
    **CRITICAL INSTRUCTION: Your entire response MUST be in KOREAN and in Key-Value format with '|||' as separator.**
    
    Key-Value Format Example:
    success_factor_1: (ê°€ì¥ í•µì‹¬ì ì¸ ì„±ê³µ ìš”ì¸ 1)
    |||
    success_factor_2: (ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ì„±ê³µ ìš”ì¸ 2)
    |||
    key_takeaway: (ì´ ê²Œì‹œë¬¼ë¡œë¶€í„° ì–»ì„ ìˆ˜ ìˆëŠ” ê°€ì¥ ì¤‘ìš”í•œ êµí›ˆê³¼ ë‹¤ìŒ ì•¡ì…˜ ì•„ì´í…œ)
    |||
    original_post_url: {post['post_url']}
    """
    
    try:
        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a content strategist specializing in social media performance analysis."},
                {"role": "user", "content": success_prompt}
            ],
            temperature=0.3,
            max_tokens=800
        )
        
        success_text = response.choices[0].message.content
        print(f"    ğŸ¤– LLM ì„±ê³µ ìš”ì¸ ë¶„ì„ ì™„ë£Œ")
        
        # Key-Value í˜•ì‹ íŒŒì‹±
        success_data = {"original_post_url": post['post_url']}
        
        # '|||'ë¡œ ë¶„í• í•˜ì—¬ íŒŒì‹±
        pairs = success_text.split('|||')
        for pair in pairs:
            if ':' in pair:
                key, value = pair.split(':', 1)
                key = key.strip()
                value = value.strip()
                success_data[key] = value
        
        return success_data
        
    except Exception as e:
        print(f"    âŒ LLM ì„±ê³µ ìš”ì¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        # API ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
        return {
            "success_factor_1": "ìš°ìˆ˜í•œ ì‹œê°ì  êµ¬ì„±ê³¼ ë¸Œëœë“œ ì¼ê´€ì„±",
            "success_factor_2": "íš¨ê³¼ì ì¸ í•´ì‹œíƒœê·¸ í™œìš©ê³¼ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ ê³ ë ¤",
            "key_takeaway": "ì´ ê²Œì‹œë¬¼ì˜ ì„±ê³µ ìš”ì†Œë¥¼ í–¥í›„ ì½˜í…ì¸ ì— ì ìš© í•„ìš”",
            "original_post_url": post['post_url']
        }