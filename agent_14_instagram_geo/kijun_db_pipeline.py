"""
KIJUN Instagram DB ê¸°ë°˜ íŒŒì´í”„ë¼ì¸
- DBì—ì„œ Instagram ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
- ê³µì‹/UGC ê²Œì‹œë¬¼ êµ¬ë¶„ ì²˜ë¦¬
- E-E-A-T-GEO ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±
- ê²°ê³¼ë¥¼ modular_agents/outputs/ì— ì €ì¥
"""
import os
import json
import sys
import requests
from PIL import Image, ImageDraw, ImageFont
import textwrap
from dotenv import load_dotenv
from openai import OpenAI
from pathlib import Path

# í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜: agent_14_instagram_geo/kijun_db_pipeline.py
# ëª©í‘œ: modular_agents/database/utils/connection.py
current_dir = Path(__file__).parent  # agent_14_instagram_geo
modular_agents_dir = current_dir.parent  # modular_agents

# ì§ì ‘ database connection íŒŒì¼ì„ import
import importlib.util
connection_path = modular_agents_dir / "database" / "utils" / "connection.py"
spec = importlib.util.spec_from_file_location("connection", connection_path)
connection_module = importlib.util.module_from_spec(spec)

# database configë„ í•„ìš”í•˜ë¯€ë¡œ ì¶”ê°€
config_path = modular_agents_dir / "database" / "config.py"
config_spec = importlib.util.spec_from_file_location("config", config_path)
config_module = importlib.util.module_from_spec(config_spec)
config_spec.loader.exec_module(config_module)

# connection ëª¨ë“ˆì—ì„œ configë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
sys.modules['config'] = config_module
spec.loader.exec_module(connection_module)

get_db = connection_module.get_db

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def get_korean_font(size=24):
    """í•œê¸€ í°íŠ¸ ê°€ì ¸ì˜¤ê¸° (Windows, Mac ì§€ì›)"""
    try:
        import platform
        system = platform.system()
        
        if system == 'Windows':
            font_paths = [
                "C:/Windows/Fonts/malgun.ttf",      # ë§‘ì€ ê³ ë”•
                "C:/Windows/Fonts/malgunbd.ttf",    # ë§‘ì€ ê³ ë”• Bold
                "C:/Windows/Fonts/gulim.ttc",       # êµ´ë¦¼
            ]
        elif system == 'Darwin':  # Mac
            font_paths = [
                "/System/Library/Fonts/AppleSDGothicNeo.ttc",
                "/Library/Fonts/AppleGothic.ttf",
                "/System/Library/Fonts/Helvetica.ttc",
            ]
        else:  # Linux
            font_paths = [
                "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            ]
        
        for font_path in font_paths:
            try:
                if os.path.exists(font_path):
                    font = ImageFont.truetype(font_path, size)
                    print(f"âœ… í•œê¸€ í°íŠ¸ ë°œê²¬: {os.path.basename(font_path)}")
                    return font
            except:
                continue
        
        print("âš ï¸ ì‹œìŠ¤í…œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return ImageFont.load_default()
        
    except Exception as e:
        print(f"âš ï¸ í°íŠ¸ ë¡œë”© ì˜¤ë¥˜: {e}")
        return ImageFont.load_default()

def load_instagram_data_from_db(brand_name='kijun'):
    """DBì—ì„œ Instagram ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"""
    print(f"\nğŸ“Š DBì—ì„œ {brand_name} Instagram ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°")
    
    try:
        db = get_db()
        
        # ê³µì‹ ê²Œì‹œë¬¼ ì¡°íšŒ
        official_posts = db.execute("""
            SELECT post_id, post_url, caption, hashtags, mentions, 
                   like_count, comment_count, posted_at, content_type,
                   media_urls, thumbnail_url
            FROM 03_raw_instagram_data 
            WHERE brand_name = %s AND content_type = 'official'
            ORDER BY posted_at DESC
        """, (brand_name,))
        
        # UGC ê²Œì‹œë¬¼ ì¡°íšŒ
        ugc_posts = db.execute("""
            SELECT post_id, post_url, caption, hashtags, mentions, 
                   like_count, comment_count, posted_at, content_type,
                   media_urls, thumbnail_url
            FROM 03_raw_instagram_data 
            WHERE brand_name = %s AND content_type = 'ugc'
            ORDER BY posted_at DESC
        """, (brand_name,))
        
        print(f"âœ… ê³µì‹ ê²Œì‹œë¬¼: {len(official_posts)}ê°œ")
        print(f"âœ… UGC ê²Œì‹œë¬¼: {len(ugc_posts)}ê°œ")
        
        # JSON í˜•íƒœë¡œ ë³€í™˜
        def convert_db_to_json(posts):
            converted = []
            for post in posts:
                try:
                    # JSON í•„ë“œ íŒŒì‹±
                    hashtags = json.loads(post['hashtags']) if post['hashtags'] else []
                    mentions = json.loads(post['mentions']) if post['mentions'] else []
                    media_urls = json.loads(post['media_urls']) if post['media_urls'] else []
                    
                    converted_post = {
                        'href': post['post_url'],
                        'post_id': post['post_id'],
                        'content': post['caption'] or '',
                        'date': post['posted_at'].strftime('%Y-%m-%d') if post['posted_at'] else '',
                        'like_count': post['like_count'] or 0,
                        'comment_count': post['comment_count'] or 0,
                        'hashtags': hashtags,
                        'mentions': mentions,
                        'img': media_urls,
                        'comments': [],  # ì‹¤ì œ ëŒ“ê¸€ ë°ì´í„°ëŠ” ë³„ë„ ìˆ˜ì§‘ í•„ìš”
                        'content_type': post['content_type']
                    }
                    converted.append(converted_post)
                except Exception as e:
                    print(f"âš ï¸ ê²Œì‹œë¬¼ ë³€í™˜ ì˜¤ë¥˜: {e}")
                    continue
            return converted
        
        official_data = convert_db_to_json(official_posts)
        ugc_data = convert_db_to_json(ugc_posts)
        
        return official_data, ugc_data
        
    except Exception as e:
        print(f"âŒ DB ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return [], []

def analyze_posts_with_llm(posts_data, is_ugc=False):
    """LLMì„ ì‚¬ìš©í•œ ê²Œì‹œë¬¼ ë¶„ì„"""
    print(f"\nğŸ¤– {'UGC' if is_ugc else 'ê³µì‹'} ê²Œì‹œë¬¼ LLM ë¶„ì„ ì‹œì‘")
    
    # API í‚¤ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ OpenAI API í‚¤ê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    client = OpenAI(api_key=api_key)
    detailed_analyses = []
    
    for i, post in enumerate(posts_data, 1):
        print(f"ğŸ“ ê²Œì‹œë¬¼ {i}/{len(posts_data)} ë¶„ì„ ì¤‘...")
        
        url = post.get('href', '')
        content = post.get('content', '')
        date = post.get('date', '')
        like_count = post.get('like_count', 0)
        comment_count = post.get('comment_count', 0)
        
        print(f"  ğŸ“ URL: {url[:50]}...")
        print(f"  ğŸ’– ì¢‹ì•„ìš”: {like_count}, ğŸ’¬ ëŒ“ê¸€: {comment_count}")
        
        if is_ugc:
            # UGC ë¶„ì„ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""
            You are a 'Senior Marketing Strategist' analyzing a KIJUN brand UGC Instagram post.
            Perform comprehensive analysis and provide scoring.
            
            POST DATA:
            URL: {url}
            Caption: {content}
            Date: {date}
            Likes: {like_count}
            Comments: {comment_count}
            
            Analyze TPO (Time, Place, Occasion), styling creativity, and user sentiment.
            
            Provide analysis in JSON format with Korean explanations:
            {{
                "product_analysis": "ì œí’ˆ ë¶„ì„",
                "tpo_score": ì ìˆ˜ (0-100),
                "tpo_reason": "TPO ì ì ˆì„± ë¶„ì„",
                "styling_score": ì ìˆ˜ (0-100),
                "styling_reason": "ìŠ¤íƒ€ì¼ë§ ì°½ì˜ì„± ë¶„ì„",
                "sentiment_score": ì ìˆ˜ (0-100),
                "sentiment_reason": "ì‚¬ìš©ì ê°ì • ë° ë§Œì¡±ë„ ë¶„ì„",
                "brand_relevance": ì ìˆ˜ (0-100),
                "brand_reason": "ë¸Œëœë“œ ì—°ê´€ì„± ë¶„ì„",
                "visual_appeal": ì ìˆ˜ (0-100),
                "visual_reason": "ì‹œê°ì  ë§¤ë ¥ë„ ë¶„ì„",
                "overall_score": í‰ê· ì ìˆ˜ (0-100),
                "summary": "ì „ì²´ ìš”ì•½",
                "improvement_suggestions": "ê°œì„  ì œì•ˆ"
            }}
            """
        else:
            # ê³µì‹ ê²Œì‹œë¬¼ E-E-A-T-GEO ë¶„ì„ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""
            You are a 'Senior Digital Marketing Analyst' analyzing official KIJUN Instagram content.
            Perform comprehensive E-E-A-T-GEO analysis.
            
            POST DATA:
            URL: {url}
            Caption: {content}
            Date: {date}
            Likes: {like_count}
            Comments: {comment_count}
            
            ANALYSIS FRAMEWORK (E-E-A-T-GEO):
            - Experience: User experience quality
            - Expertise: Fashion expertise demonstration  
            - Authoritativeness: Brand authority signals
            - Trustworthiness: Content credibility
            - Geographic: Location/cultural relevance
            
            Provide analysis in JSON format with Korean explanations:
            {{
                "experience_score": ì ìˆ˜ (0-100),
                "experience_reason": "ì‚¬ìš©ì ê²½í—˜ í’ˆì§ˆ ë¶„ì„",
                "expertise_score": ì ìˆ˜ (0-100),
                "expertise_reason": "íŒ¨ì…˜ ì „ë¬¸ì„± ë¶„ì„",
                "authoritativeness_score": ì ìˆ˜ (0-100),
                "authoritativeness_reason": "ë¸Œëœë“œ ê¶Œìœ„ì„± ë¶„ì„",
                "trustworthiness_score": ì ìˆ˜ (0-100),
                "trustworthiness_reason": "ì½˜í…ì¸  ì‹ ë¢°ì„± ë¶„ì„",
                "geographic_score": ì ìˆ˜ (0-100),
                "geographic_reason": "ì§€ë¦¬ì /ë¬¸í™”ì  ì—°ê´€ì„± ë¶„ì„",
                "overall_score": í‰ê· ì ìˆ˜ (0-100),
                "summary": "E-E-A-T-GEO ì „ì²´ ë¶„ì„ ìš”ì•½",
                "improvement_suggestions": "ì½˜í…ì¸  ê°œì„  ì œì•ˆ"
            }}
            """
        
        try:
            # OpenAI API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert marketing analyst specializing in Instagram content analysis."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            analysis_text = response.choices[0].message.content
            
            # JSON íŒŒì‹±
            try:
                import re
                json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
                json_matches = re.findall(json_pattern, analysis_text, re.DOTALL)
                
                if json_matches:
                    json_text = max(json_matches, key=len)
                    analysis_json = json.loads(json_text)
                else:
                    json_start = analysis_text.find('{')
                    json_end = analysis_text.rfind('}') + 1
                    if json_start != -1 and json_end > json_start:
                        json_text = analysis_text[json_start:json_end]
                        analysis_json = json.loads(json_text)
                    else:
                        raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
            except Exception as json_error:
                print(f"  âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                analysis_json = {
                    "overall_score": 75,
                    "summary": f"ê²Œì‹œë¬¼ {i} ë¶„ì„ ì™„ë£Œ (íŒŒì‹± ì˜¤ë¥˜)",
                    "improvement_suggestions": "ë¶„ì„ ë°ì´í„° í™•ì¸ í•„ìš”"
                }
            
        except Exception as e:
            print(f"  âŒ LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
            analysis_json = {
                "overall_score": 75,
                "summary": f"ê²Œì‹œë¬¼ {i} ë¶„ì„ ì˜¤ë¥˜",
                "improvement_suggestions": "ë¶„ì„ ì¬ì‹œë„ í•„ìš”"
            }
        
        post_analysis = {
            "post_data": post,
            "analysis": analysis_json,
            "content_type": post.get('content_type', 'official')
        }
        
        detailed_analyses.append(post_analysis)
        score = analysis_json.get('overall_score', 75)
        print(f"  âœ… ì™„ë£Œ - ì ìˆ˜: {score}/100ì ")
    
    return detailed_analyses

def generate_improvement_suggestions(low_score_posts):
    """í•˜ìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ì— ëŒ€í•œ ê°œì„ ì•ˆ ìƒì„±"""
    print(f"\nğŸ’¡ í•˜ìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ê°œì„ ì•ˆ ìƒì„± ì¤‘...")
    
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        return []
    
    client = OpenAI(api_key=api_key)
    suggestions = []
    
    for post in low_score_posts:
        post_data = post['post_data']
        analysis = post['analysis']
        
        revision_prompt = f"""
        You are a senior Creative Director for KIJUN fashion brand.
        Create improved content for an underperforming Instagram post.
        
        ORIGINAL POST:
        Caption: {post_data.get('content', '')}
        Score: {analysis.get('overall_score', 0)}
        Issues: {analysis.get('improvement_suggestions', '')}
        
        Create improved content in Korean Key-Value format with '|||' separator:
        
        new_caption_v1: (ê°œì„ ëœ ìº¡ì…˜ ë²„ì „ 1)
        |||
        new_caption_v2: (ê°œì„ ëœ ìº¡ì…˜ ë²„ì „ 2)
        |||
        hashtags: #í‚¤ì¤€ #KIJUN #íŒ¨ì…˜ #ìŠ¤íƒ€ì¼ (ìµœì í™”ëœ í•´ì‹œíƒœê·¸)
        |||
        new_image_idea: (ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì»¨ì…‰ ì•„ì´ë””ì–´)
        |||
        improvement_focus: (ì£¼ìš” ê°œì„  í¬ì¸íŠ¸)
        """
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a creative director specializing in fashion brand content."},
                    {"role": "user", "content": revision_prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            revision_text = response.choices[0].message.content
            
            # Key-Value í˜•ì‹ íŒŒì‹±
            revision_data = {"original_post_url": post_data.get('href', '')}
            
            pairs = revision_text.split('|||')
            for pair in pairs:
                if ':' in pair:
                    key, value = pair.split(':', 1)
                    revision_data[key.strip()] = value.strip()
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            if 'new_caption_v1' not in revision_data:
                revision_data['new_caption_v1'] = "KIJUNì˜ ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ì„ ë§Œë‚˜ë³´ì„¸ìš”! ì„¸ë ¨ëœ ë””ìì¸ê³¼ í¸ì•ˆí•œ ì°©ìš©ê°ì´ ì¡°í™”ë¥¼ ì´ë£¬ í”„ë¦¬ë¯¸ì—„ íŒ¨ì…˜ì„ ê²½í—˜í•´ë³´ì„¸ìš”. âœ¨"
            
            if 'hashtags' not in revision_data:
                revision_data['hashtags'] = "#í‚¤ì¤€ #KIJUN #íŒ¨ì…˜ #ìŠ¤íƒ€ì¼ #ì‹ ìƒí’ˆ #í”„ë¦¬ë¯¸ì—„"
            
            suggestions.append(revision_data)
            
        except Exception as e:
            print(f"    âŒ ê°œì„ ì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            suggestions.append({
                "new_caption_v1": "KIJUNì˜ ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ì„ ë§Œë‚˜ë³´ì„¸ìš”!",
                "hashtags": "#í‚¤ì¤€ #KIJUN #íŒ¨ì…˜",
                "original_post_url": post_data.get('href', '')
            })
    
    return suggestions

def create_output_directory():
    """modular_agents/outputs ë””ë ‰í† ë¦¬ ìƒì„±"""
    output_dir = Path(__file__).parent.parent / "outputs"
    output_dir.mkdir(exist_ok=True)
    return output_dir

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ KIJUN Instagram DB ê¸°ë°˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 60)
    
    # API í‚¤ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ OpenAI API í‚¤ê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = create_output_directory()
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    try:
        # 1. DBì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        official_posts, ugc_posts = load_instagram_data_from_db('kijun')
        
        if not official_posts and not ugc_posts:
            print("âŒ DBì—ì„œ Instagram ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # 2. ê³µì‹ ê²Œì‹œë¬¼ ë¶„ì„
        official_analyses = []
        if official_posts:
            official_analyses = analyze_posts_with_llm(official_posts, is_ugc=False)
        
        # 3. UGC ê²Œì‹œë¬¼ ë¶„ì„
        ugc_analyses = []
        if ugc_posts:
            ugc_analyses = analyze_posts_with_llm(ugc_posts, is_ugc=True)
        
        # 4. í†µí•© ë¶„ì„ ê²°ê³¼ ìƒì„±
        all_analyses = official_analyses + ugc_analyses
        
        # ì ìˆ˜ë³„ ì •ë ¬
        sorted_analyses = sorted(all_analyses, key=lambda x: x['analysis']['overall_score'])
        
        # í•˜ìœ„/ìƒìœ„ ê²Œì‹œë¬¼ ì„ ë³„
        low_score_posts = sorted_analyses[:2] if len(sorted_analyses) >= 2 else sorted_analyses
        high_score_posts = sorted_analyses[-2:] if len(sorted_analyses) >= 2 else sorted_analyses
        
        # 5. ê°œì„ ì•ˆ ìƒì„±
        improvement_suggestions = generate_improvement_suggestions(low_score_posts)
        
        # 6. ê²°ê³¼ ì €ì¥
        timestamp = Path(__file__).name.replace('.py', '')
        
        # ì „ì²´ ë¶„ì„ ê²°ê³¼
        analysis_result = {
            "analysis_summary": {
                "total_posts": len(all_analyses),
                "official_posts": len(official_analyses),
                "ugc_posts": len(ugc_analyses),
                "average_score": sum(a['analysis']['overall_score'] for a in all_analyses) / len(all_analyses) if all_analyses else 0
            },
            "detailed_analyses": all_analyses,
            "low_score_posts": low_score_posts,
            "high_score_posts": high_score_posts,
            "improvement_suggestions": improvement_suggestions
        }
        
        # íŒŒì¼ ì €ì¥
        analysis_file = output_dir / f"kijun_instagram_db_analysis_{timestamp}.json"
        with open(analysis_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {analysis_file}")
        print(f"ğŸ“ˆ ì´ ê²Œì‹œë¬¼: {len(all_analyses)}ê°œ")
        print(f"ğŸ“ˆ í‰ê·  ì ìˆ˜: {analysis_result['analysis_summary']['average_score']:.1f}ì ")
        
        return True
        
    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main()