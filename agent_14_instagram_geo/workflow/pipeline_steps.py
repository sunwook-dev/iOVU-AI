"""
KIJUN Instagram ì™„ì „ í†µí•© íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ì›Œí¬í”Œë¡œìš°
"""
import os
from utils.file_utils import (
    load_json_data, save_json_data, check_file_exists, 
    get_file_size_kb, ensure_directory_exists, extract_base_filename,
    get_ugc_type_from_filename
)
from tools.eeat_analyzer import EEATGeoAnalyzer
from tools.content_optimizer import ContentOptimizer
from tools.image_generator import ImageGenerator
from tools.mockup_generator import InstagramMockupGenerator


class InstagramAnalysisStep:
    """1ë‹¨ê³„: E-E-A-T-GEO ë¶„ì„ ë‹¨ê³„"""
    
    def __init__(self, api_key):
        self.analyzer = EEATGeoAnalyzer(api_key)
        self.optimizer = ContentOptimizer(api_key)
    
    def execute(self, input_files=['kijun_official_tagged.json', 'kijun_official.json']):
        """E-E-A-T-GEO ë¶„ì„ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print("1ë‹¨ê³„: KIJUN Instagram ìƒì„¸ E-E-A-T-GEO ë¶„ì„ ì‹œì‘")
        print(f"{'='*60}")
        
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œì¸ì§€ í™•ì¸
        if len(input_files) == 1:
            filename = input_files[0]
            print(f"ğŸ“„ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ: {filename}")
            processed_file = self._process_single_file(filename)
            if processed_file:
                return processed_file['content_file']
            else:
                return None
        
        # ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ (ê¸°ì¡´ ë°©ì‹)
        processed_files = []
        
        for filename in input_files:
            if not check_file_exists(filename):
                print(f"âš ï¸ {filename} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                continue
            
            processed_file = self._process_single_file(filename)
            if processed_file:
                processed_files.append(processed_file)
        
        if not processed_files:
            print(f"âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"\nğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
        print(f"=" * 60)
        print(f"ğŸ“Š **ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½**")
        
        for file_info in processed_files:
            print(f"ğŸ“ {file_info['input_file']} ({'UGC' if file_info['is_ugc'] else 'ê³µì‹'}):")
            print(f"  - ê²Œì‹œë¬¼ ìˆ˜: {file_info['post_count']}ê°œ")
            print(f"  - ë¶„ì„ íŒŒì¼: {file_info['analysis_file']}")
            print(f"  - ì½˜í…ì¸  íŒŒì¼: {file_info['content_file']}")
        
        return processed_files[0]['content_file']
    
    def _process_single_file(self, filename):
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        try:
            print(f"\nğŸ”„ {filename} ì²˜ë¦¬ ì‹œì‘...")
            
            data = load_json_data(filename)
            if not data:
                return None
            
            is_ugc_dataset = get_ugc_type_from_filename(filename)
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {filename} ({len(data)}ê°œ ê²Œì‹œë¬¼)")
            print(f"ğŸ“‹ ë°ì´í„°ì…‹ ìœ í˜•: {'UGC í¬í•¨' if is_ugc_dataset else 'ê³µì‹ ê²Œì‹œë¬¼ ì „ìš©'}")
            
            detailed_analyses = []
            
            # ëª¨ë“  ê²Œì‹œë¬¼ ë¶„ì„
            for i, post in enumerate(data, 1):
                print(f"ğŸ“ ê²Œì‹œë¬¼ {i}/{len(data)} ìƒì„¸ ë¶„ì„ ì¤‘...")
                
                analysis_result = self._analyze_post(post, i, is_ugc_dataset)
                if analysis_result:
                    detailed_analyses.append(analysis_result)
            
            # ì½˜í…ì¸  ìµœì í™” ì œì•ˆ ìƒì„±
            content_suggestions = self._generate_content_suggestions(detailed_analyses)
            
            # íŒŒì¼ ì €ì¥
            return self._save_analysis_results(filename, detailed_analyses, content_suggestions, is_ugc_dataset)
            
        except Exception as e:
            print(f"âŒ {filename} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _analyze_post(self, post, post_number, is_ugc):
        """ë‹¨ì¼ ê²Œì‹œë¬¼ ë¶„ì„"""
        try:
            print(f"  ğŸ¤– AI ìƒì„¸ ë¶„ì„ ì¤‘...")
            
            if is_ugc:
                analysis_json = self.analyzer.analyze_ugc_post(post)
            else:
                analysis_json = self.analyzer.analyze_official_post(post)
            
            if not analysis_json:
                return None
            
            # ë¶„ì„ ê²°ê³¼ êµ¬ì¡°í™”
            post_analysis = self._structure_analysis_result(post, post_number, analysis_json, is_ugc)
            
            print(f"  âœ… ì™„ë£Œ - ì ìˆ˜: {analysis_json.get('overall_score', 0):.1f}/100ì ")
            return post_analysis
            
        except Exception as e:
            print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    def _structure_analysis_result(self, post, post_number, analysis_json, is_ugc):
        """ë¶„ì„ ê²°ê³¼ êµ¬ì¡°í™”"""
        url = post.get('href', '')
        content = post.get('content', '')
        date = post.get('date', '')
        comments = post.get('comments', [])
        
        post_analysis = {
            "post_url": url,
            "original_post_data": {
                "number": post_number,
                "href": url,
                "date": date,
                "content": content,
                "img": post.get('img', []),
                "comments": comments
            },
            "post_summary": {
                "summary": analysis_json.get('summary', ''),
                "overall_score": analysis_json.get('overall_score', 0),
                "category_averages": analysis_json.get('category_averages', {}),
                "overall_suggestion": analysis_json.get('overall_suggestion', '')
            }
        }
        
        if is_ugc:
            post_analysis["ugc_analysis"] = {
                "product_guess": analysis_json.get('product_guess', ''),
                "tpo_analysis": analysis_json.get('tpo_analysis', ''),
                "tpo_score": str(analysis_json.get('tpo_score', 0)),
                "tpo_reason": analysis_json.get('tpo_reason', ''),
                "styling_mood": analysis_json.get('styling_mood', ''),
                "paired_items": analysis_json.get('paired_items', ''),
                "styling_score": str(analysis_json.get('styling_score', 0)),
                "styling_reason": analysis_json.get('styling_reason', ''),
                "sentiment_score": str(analysis_json.get('sentiment_score', 0)),
                "sentiment_reason": analysis_json.get('sentiment_reason', ''),
                "brand_relevance": str(analysis_json.get('brand_relevance', 0)),
                "brand_reason": analysis_json.get('brand_reason', ''),
                "visual_appeal": str(analysis_json.get('visual_appeal', 0)),
                "visual_reason": analysis_json.get('visual_reason', ''),
                "synergy_score": str(analysis_json.get('synergy_score', 0)),
                "synergy_reason": analysis_json.get('synergy_reason', '')
            }
        else:
            post_analysis["synergy_analysis"] = {
                "visual_coherence_score": str(analysis_json.get('visual_coherence_score', 0)),
                "visual_coherence_reason": analysis_json.get('visual_coherence_reason', ''),
                "narrative_flow_score": str(analysis_json.get('narrative_flow_score', 0)),
                "narrative_flow_reason": analysis_json.get('narrative_flow_reason', ''),
                "alignment_with_caption_score": str(analysis_json.get('alignment_with_caption_score', 0)),
                "alignment_with_caption_reason": analysis_json.get('alignment_with_caption_reason', '')
            }
            
            post_analysis["eeat_geo_analysis"] = {
                "experience_score": str(analysis_json.get('experience_score', 0)),
                "experience_reason": analysis_json.get('experience_reason', ''),
                "expertise_score": str(analysis_json.get('expertise_score', 0)),
                "expertise_reason": analysis_json.get('expertise_reason', ''),
                "authoritativeness_score": str(analysis_json.get('authoritativeness_score', 0)),
                "authoritativeness_reason": analysis_json.get('authoritativeness_reason', ''),
                "trustworthiness_score": str(analysis_json.get('trustworthiness_score', 0)),
                "trustworthiness_reason": analysis_json.get('trustworthiness_reason', ''),
                "geo_clarity_score": str(analysis_json.get('geo_clarity_score', 0)),
                "geo_clarity_reason": analysis_json.get('geo_clarity_reason', ''),
                "geo_structure_score": str(analysis_json.get('geo_structure_score', 0)),
                "geo_structure_reason": analysis_json.get('geo_structure_reason', ''),
                "geo_context_score": str(analysis_json.get('geo_context_score', 0)),
                "geo_context_reason": analysis_json.get('geo_context_reason', ''),
                "geo_alignment_score": str(analysis_json.get('geo_alignment_score', 0)),
                "geo_alignment_reason": analysis_json.get('geo_alignment_reason', ''),
                "geo_timeliness_score": str(analysis_json.get('geo_timeliness_score', 0)),
                "geo_timeliness_reason": analysis_json.get('geo_timeliness_reason', ''),
                "geo_originality_score": str(analysis_json.get('geo_originality_score', 0)),
                "geo_originality_reason": analysis_json.get('geo_originality_reason', '')
            }
        
        post_analysis["individual_analyses"] = [{
            "overall_suggestion": analysis_json.get('overall_suggestion', '')
        }]
        
        return post_analysis
    
    def _generate_content_suggestions(self, detailed_analyses):
        """ì½˜í…ì¸  ê°œì„  ì œì•ˆ ìƒì„±"""
        sorted_analyses = sorted(detailed_analyses, key=lambda x: x['post_summary']['overall_score'])
        
        # í•˜ìœ„/ìƒìœ„ ì„ íƒ
        low_score_posts = sorted_analyses[:2] if len(sorted_analyses) >= 2 else sorted_analyses[:1]
        high_score_posts = sorted_analyses[-2:] if len(sorted_analyses) >= 2 else sorted_analyses[-1:]
        
        print(f"\nğŸ’¡ ê°œì„ ëœ ì½˜í…ì¸  ì œì•ˆ ìƒì„± ì¤‘...")
        
        low_score_revisions = []
        high_score_analyses = []
        
        # í•˜ìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ê°œì„ ì•ˆ
        for post in low_score_posts:
            print(f"  ğŸ“ í•˜ìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ê°œì„ ì•ˆ ìƒì„± ì¤‘...")
            revision_json = self.optimizer.generate_content_revision(post)
            if revision_json:
                low_score_revisions.append(revision_json)
        
        # ìƒìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ì„±ê³µ ìš”ì¸ ë¶„ì„
        for post in high_score_posts:
            print(f"  ğŸ† ìƒìœ„ ì ìˆ˜ ê²Œì‹œë¬¼ ì„±ê³µ ìš”ì¸ ë¶„ì„ ì¤‘...")
            success_json = self.optimizer.analyze_success_factors(post)
            if success_json:
                high_score_analyses.append(success_json)
        
        return {
            "low_score_revisions": low_score_revisions,
            "high_score_analyses": high_score_analyses
        }
    
    def _save_analysis_results(self, filename, detailed_analyses, content_suggestions, is_ugc_dataset):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        ugc_count = len([p for p in detailed_analyses if 'ugc_analysis' in p])
        has_ugc = ugc_count > 0
        
        print(f"\nğŸ“Š {filename} ë¶„ì„ ê²°ê³¼ êµ¬ì„±:")
        print(f"  - ì „ì²´ ê²Œì‹œë¬¼: {len(detailed_analyses)}ê°œ")
        print(f"  - UGC ê²Œì‹œë¬¼: {ugc_count}ê°œ")
        print(f"  - ê³µì‹ ê²Œì‹œë¬¼: {len(detailed_analyses) - ugc_count}ê°œ")
        
        # íŒŒì¼ëª… ê²°ì •
        base_name = filename.replace('.json', '')
        if has_ugc:
            eeatg_filename = f'{base_name}_ugc_combined_analysis.json'
            content_filename = f'{base_name}_ugc_generated_content.json'
            print(f"ğŸ’¡ UGC í¬í•¨ ë¶„ì„ìœ¼ë¡œ íŒŒì¼ëª…: {eeatg_filename}")
        else:
            eeatg_filename = f'{base_name}_eeatg_analysis.json'
            content_filename = f'{base_name}_generated_content.json'
            print(f"ğŸ’¡ ê³µì‹ ê²Œì‹œë¬¼ ì „ìš© ë¶„ì„ íŒŒì¼ëª…: {eeatg_filename}")
        
        # Always save to modular_agents/outputs directory
        from pathlib import Path
        current_file = Path(__file__)  # agent_14_instagram_geo/workflow/pipeline_steps.py
        modular_agents_dir = current_file.parent.parent.parent  # Go up to modular_agents
        output_path = modular_agents_dir / "outputs"
        output_path.mkdir(parents=True, exist_ok=True)
        
        eeatg_filepath = output_path / eeatg_filename
        content_filepath = output_path / content_filename
        
        # íŒŒì¼ ì €ì¥
        save_json_data(detailed_analyses, str(eeatg_filepath))
        save_json_data(content_suggestions, str(content_filepath))
        
        print(f"âœ… {filename} ì²˜ë¦¬ ì™„ë£Œ - íŒŒì¼ ì €ì¥: {eeatg_filename}, {content_filename}")
        
        return {
            'input_file': filename,
            'analysis_file': eeatg_filename,
            'content_file': content_filename,
            'is_ugc': is_ugc_dataset,
            'post_count': len(detailed_analyses)
        }


class ImageGenerationStep:
    """2ë‹¨ê³„: ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„"""
    
    def __init__(self, api_key):
        self.generator = ImageGenerator(api_key)
    
    def execute(self, content_filename):
        """ì´ë¯¸ì§€ ìƒì„± ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print("2ë‹¨ê³„: ì €ì¥ëœ ì•„ì´ë””ì–´ë¡œ ìµœì¢… ì´ë¯¸ì§€ ìƒì„±")
        print(f"{'='*60}")
        
        try:
            data = load_json_data(content_filename)
            if not data:
                return None
            
            low_score_revisions = data.get('low_score_revisions', [])
            
            if not low_score_revisions:
                print("âš ï¸ low_score_revisions ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ì²« ë²ˆì§¸ í•­ëª©ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±
            draft = low_score_revisions[0]
            print(f"ğŸ“ ì´ë¯¸ì§€ ìƒì„± ëŒ€ìƒ: {draft.get('original_post_url', 'Unknown')}")
            
            image_generation_prompt = draft.get('new_image_idea', '')
            
            if image_generation_prompt:
                return self.generator.generate_image_from_idea(image_generation_prompt)
            else:
                print("âŒ new_image_ideaë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
                
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return None


class MockupGenerationStep:
    """3ë‹¨ê³„: Instagram ëª©ì—… ìƒì„± ë‹¨ê³„"""
    
    def __init__(self, images_folder="./images"):
        self.generator = InstagramMockupGenerator(images_folder)
    
    def execute(self, image_path, content_filename):
        """ëª©ì—… ìƒì„± ì‹¤í–‰ - UGC/ë¹„-UGC ë³„ë„ ì²˜ë¦¬"""
        print(f"\n{'='*60}")
        print("3ë‹¨ê³„: Instagram ê²Œì‹œë¬¼ ëª©ì—… ìƒì„±")
        print(f"{'='*60}")
        
        try:
            # ì²˜ë¦¬ëœ íŒŒì¼ëª…ì—ì„œ ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ
            base_filename = extract_base_filename(content_filename)
            
            # JSON ë°ì´í„° ë¡œë“œ
            data = load_json_data(content_filename)
            if not data:
                return None
            
            mockup_paths = []
            
            # UGC ë°ì´í„° í™•ì¸
            is_ugc_content = 'ugc' in content_filename.lower()
            
            if is_ugc_content:
                print("ğŸ“± UGC ì½˜í…ì¸  ëª©ì—… ìƒì„±...")
                # UGC ì „ìš© ëª©ì—… ìƒì„±
                mockup_path = self._create_ugc_mockup(data, base_filename, image_path)
                if mockup_path:
                    mockup_paths.append(mockup_path)
            else:
                print("ğŸ“± ê³µì‹ ì½˜í…ì¸  ëª©ì—… ìƒì„±...")
                # ê³µì‹ ì½˜í…ì¸  ì „ìš© ëª©ì—… ìƒì„±
                mockup_path = self._create_official_mockup(data, base_filename, image_path)
                if mockup_path:
                    mockup_paths.append(mockup_path)
            
            print(f"âœ… ì´ {len(mockup_paths)}ê°œì˜ ëª©ì—…ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return mockup_paths[0] if mockup_paths else None
            
        except Exception as e:
            print(f"âŒ Instagram ëª©ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _create_ugc_mockup(self, data, base_filename, image_path):
        """UGC ì „ìš© ëª©ì—… ìƒì„±"""
        try:
            caption_data = data['low_score_revisions'][0]
            # UGCëŠ” ë” ê°œì¸ì ì¸ v2 ìº¡ì…˜ ì„ íƒ
            caption_text = caption_data.get('new_caption_v2', caption_data.get('new_caption_v1', ''))
            hashtags_text = caption_data['hashtags']
            
            # UGC ëª©ì—… íŒŒì¼ëª… - modular_agents/outputsì— ì €ì¥
            from pathlib import Path
            current_file = Path(__file__)  # agent_14_instagram_geo/workflow/pipeline_steps.py
            modular_agents_dir = current_file.parent.parent.parent  # Go up to modular_agents
            output_path = modular_agents_dir / "outputs"
            output_path.mkdir(parents=True, exist_ok=True)
            output_filename = str(output_path / f"{base_filename}_ugc_instagram_mockup.jpg")
            
            # UGCìš© ê³„ì •ëª…ê³¼ ìŠ¤íƒ€ì¼ ì„¤ì •
            return self.generator.create_mockup(
                image_path or "dummy.jpg", 
                caption_text, 
                hashtags_text, 
                output_filename,
                account_name="tomncheese",  # UGC ê³„ì •ëª…
                account_type="ugc"
            )
        except Exception as e:
            print(f"âŒ UGC ëª©ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _create_official_mockup(self, data, base_filename, image_path):
        """ê³µì‹ ì½˜í…ì¸  ì „ìš© ëª©ì—… ìƒì„±"""
        try:
            caption_data = data['low_score_revisions'][0]
            # ê³µì‹ì€ ë” ë¸Œëœë“œì ì¸ v1 ìº¡ì…˜ ì„ íƒ
            caption_text = caption_data.get('new_caption_v1', caption_data.get('new_caption_v2', ''))
            hashtags_text = caption_data['hashtags']
            
            # ê³µì‹ ëª©ì—… íŒŒì¼ëª… - modular_agents/outputsì— ì €ì¥
            from pathlib import Path
            current_file = Path(__file__)  # agent_14_instagram_geo/workflow/pipeline_steps.py
            modular_agents_dir = current_file.parent.parent.parent  # Go up to modular_agents
            output_path = modular_agents_dir / "outputs"
            output_path.mkdir(parents=True, exist_ok=True)
            output_filename = str(output_path / f"{base_filename}_official_instagram_mockup.jpg")
            
            # ê³µì‹ ê³„ì •ëª…ê³¼ ìŠ¤íƒ€ì¼ ì„¤ì •
            return self.generator.create_mockup(
                image_path or "dummy.jpg", 
                caption_text, 
                hashtags_text, 
                output_filename,
                account_name="kijun_official",  # ê³µì‹ ê³„ì •ëª…
                account_type="official"
            )
        except Exception as e:
            print(f"âŒ ê³µì‹ ëª©ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return None
